<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Chapter 11 Continuous Response | Gov 50: Data" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="davidkane9/PPBDS" />



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="Chapter 11 Continuous Response | Gov 50: Data">

<title>Chapter 11 Continuous Response | Gov 50: Data</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />
<link href="libs/msmb-css-0/msmb.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);

e.style.display = ((e.style.display!='none') ? 'none' : 'block');

if(f.classList.contains('fa-plus-square')) {
    f.classList.add('fa-minus-square')
    f.classList.remove('fa-plus-square')
} else {
    f.classList.add('fa-plus-square')
    f.classList.remove('fa-minus-square')
}

}
</script>
<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<link href="libs/str_view-0.1.0/str_view.css" rel="stylesheet" />
<script src="libs/str_view-binding-1.4.0/str_view.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }

code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul class="navbar">
<li class="msmb"><p class="title">Gov 50: Data<p><p class="author"></p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="index.html"></a>
<a href="preamble.html">Preamble</a>
<a href="shopping-week.html">Shopping Week</a>
<a href="visualization.html"><span class="toc-section-number">1</span> Visualization</a>
<a href="wrangling.html"><span class="toc-section-number">2</span> Wrangling</a>
<a href="rubin-causal-model.html"><span class="toc-section-number">3</span> Rubin Causal Model</a>
<a href="functions.html"><span class="toc-section-number">4</span> Functions</a>
<a href="probability.html"><span class="toc-section-number">5</span> Probability</a>
<a href="one-parameter.html"><span class="toc-section-number">6</span> One Parameter</a>
<a href="two-parameters.html"><span class="toc-section-number">7</span> Two Parameters</a>
<a href="three-parameters.html"><span class="toc-section-number">8</span> Three Parameters</a>
<a href="n-parameters.html"><span class="toc-section-number">9</span> N Parameters</a>
<a href="model-choice.html"><span class="toc-section-number">10</span> Model Choice</a>
<a id="active-page" href="continuous-response.html"><span class="toc-section-number">11</span> Continuous Response</a><ul class="toc-sections">
<li class="toc"><a href="#exploratory-data-analysis"> Exploratory Data Analysis</a></li>
<li class="toc"><a href="#linear-model"> Linear model</a></li>
<li class="toc"><a href="#bayesian-linear-model"> Bayesian linear model</a></li>
<li class="toc"><a href="#neural-networks"> Neural networks</a></li>
<li class="toc"><a href="#model-comparison"> Model comparison</a></li>
<li class="toc"><a href="#cardinal-virtues-1"> Cardinal virtues</a></li>
<li class="toc"><a href="#summary-1"> Summary</a></li>
</ul>
<a href="discrete-response.html"><span class="toc-section-number">12</span> Discrete Response</a>
<a href="appendices.html">Appendices</a>
<a href="tools.html">Tools</a>
<a href="shiny.html">Shiny</a>
<a href="maps.html">Maps</a>
<a href="animation.html">Animation</a>
<a href="references.html">References</a>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html><body><div id="continuous-response" class="section level1">
<h1>
<span class="header-section-number">Chapter 11</span> Continuous Response</h1>
<!-- DK: Error message from running nn fit_resamples. -->
<!-- DK: Should, in each section, "discover" some weirdness in the plot, go back and add a step_function, and discover that the weirdness is "fixed" in the plot. -->
<!-- DK: Should we add more detail in terms of how we work with the fit_samples object? Probably not. Too complex for this class. If anything, we need more time discussing how we should investigate what step_* functions to add and why. -->
<!-- DK: Need to use our chosen model to answer a question of some sort. Let's compare group X with group Y. How do they differ in predicted ideology?  If we have enough members of group X and group Y, we can just compare their real ideology! But, often we won't have enough. So, we need to use the model to make the comparison. -->
<!-- DK: What about code like this for comparing a bunch of models all at once? -->
<!-- ```{r} -->
<!-- ch11_formulas <- tibble(formula = c(age_form, -->
<!--                                    race_gender_form, -->
<!--                                    full_form, -->
<!--                                    interact_form), -->
<!--                        group = c("Age only model", -->
<!--                                  "Race and gender model", -->
<!--                                  "Full model without interaction", -->
<!--                                  "Interaction model")) -->
<!-- ``` -->
<!-- Now, we can use `map_*` to apply all of these models and view their metrics to see which ones have the lowest rmse values. -->
<!-- ```{r cache=TRUE, message=FALSE} -->
<!-- set.seed(10) -->
<!-- folds_metrics <- ch11_formulas %>% -->
<!--   mutate(metrics = map(formula, ~ fit_resamples(object = lm_model, -->
<!--                                                 preprocessor = ., -->
<!--                                                 resamples = ch11_folds) %>% -->
<!--                          collect_metrics())) -->
<!-- ``` -->
<p>Chapter <a href="model-choice.html#model-choice">10</a> showed us the <em>tidymodels</em> framework for model building and testing. In this chapter, we will use it to explore models in which the outcome variable is <em>continuous</em>. In Chapter <a href="discrete-response.html#discrete-response">12</a>, we learn about outcome variables which are <em>discrete</em>, meaning that they are members of distinct categories like TRUE/FALSE or yes/no.</p>
<p>We use <code>nes</code> from the <code>PPBDS.data</code> package. <code>nes</code> contains data from the American National Election Survey for every presidential election year since 1952. Along with demographic details, such as race, gender, and age, the survey also includes respondents’ ideological identification. Because <code>ideology</code> is measured on a scale from -3 to 3, we can treat it as a continuous outcome variable.</p>
<div id="exploratory-data-analysis" class="section level2">
<h2>
<span class="header-section-number">11.1</span> Exploratory Data Analysis</h2>
<p>Packages:</p>
<div class="sourceCode" id="cb1088"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1088-1"><a href="continuous-response.html#cb1088-1"></a><span class="kw">library</span>(PPBDS.data)</span>
<span id="cb1088-2"><a href="continuous-response.html#cb1088-2"></a><span class="kw">library</span>(skimr)</span>
<span id="cb1088-3"><a href="continuous-response.html#cb1088-3"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb1088-4"><a href="continuous-response.html#cb1088-4"></a><span class="kw">library</span>(tidymodels)</span>
<span id="cb1088-5"><a href="continuous-response.html#cb1088-5"></a><span class="kw">library</span>(rstanarm)</span></code></pre></div>
<p>Explore <code>nes</code>:</p>
<div class="sourceCode" id="cb1089"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1089-1"><a href="continuous-response.html#cb1089-1"></a><span class="kw">glimpse</span>(nes)</span></code></pre></div>
<pre><code>## Rows: 38,558
## Columns: 11
## $ year      &lt;int&gt; 1952, 1952, 1952, 1952, 1952, 1952, 1952, 1952, 1952, 1952,…
## $ state     &lt;chr&gt; "NY", "NY", "NY", "NY", "OH", "OH", "ID", "MI", "GA", "OH",…
## $ gender    &lt;chr&gt; "Female", "Female", "Female", "Male", "Female", "Female", "…
## $ income    &lt;ord&gt; 68 - 95, 68 - 95, 34 - 67, 34 - 67, 0 - 16, 68 - 95, 0 - 16…
## $ age       &lt;ord&gt; 25 - 34, 25 - 34, 25 - 34, 55 - 64, 65 - 74, 45 - 54, 65 - …
## $ education &lt;ord&gt; Highschool, Elementary, Highschool, Some Highschool, Highsc…
## $ race      &lt;chr&gt; "White", "White", "White", "White", "White", "White", "Whit…
## $ ideology  &lt;int&gt; 2, 1, 0, 3, 3, -1, 0, -2, NA, 2, -2, 3, -1, -2, 3, -2, -3, …
## $ pres_appr &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ voted     &lt;chr&gt; "Yes", "Yes", "Yes", "Yes", "Yes", "Yes", "Yes", "Yes", "No…
## $ region    &lt;fct&gt; Northeast, Northeast, Northeast, Northeast, Midwest, Midwes…</code></pre>
<p>Variables available in <code>nes</code>. Note that the full NES has many more variables available.</p>
<!-- DK: Is voted in previous election or in this one? -->
<ul>
<li>
<code>year</code>: the year the study was conducted.</li>
<li>
<code>state</code>: abbreviation for state of residence.</li>
<li>
<code>gender</code>: identifies respondents with values “Male” and “Female”.</li>
<li>
<code>race</code>: race/ethnicity respondent identification.</li>
<li>
<code>income</code>: 5 income groups described with percentile range: 0-16, 17-33, 34 to 67, 68-95, and 96-100.</li>
<li>
<code>age</code>: ranges for respondents’ age.</li>
<li>
<code>education</code>: seven categories of educational achievement.</li>
<li>
<code>pres_appr</code>: respondents’ self-reported approval of the sitting president.</li>
<li>
<code>voted</code>: whether the respondent had voted in the presidential election.</li>
<li>
<code>ideology</code> a continuous variable with -3 corresponding to strongly Democrat and 3 corresponding to strongly Republican.</li>
<li>
<code>region</code>: US region: Northeast, Midwest, West, and South.</li>
</ul>
<p>Given knowledge of these variables for a new person, our goal is to predict their ideology correctly.</p>
<div class="sourceCode" id="cb1091"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1091-1"><a href="continuous-response.html#cb1091-1"></a><span class="kw">skim</span>(nes)</span></code></pre></div>
<p><!--
<caption>--><span class="marginnote shownote"><span id="tab:unnamed-chunk-844">TABLE 11.1: </span>Data summary</span><!--</caption>--></p>
<table><tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">nes</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">38558</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">11</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">character</td>
<td align="left">5</td>
</tr>
<tr class="odd">
<td align="left">factor</td>
<td align="left">4</td>
</tr>
<tr class="even">
<td align="left">numeric</td>
<td align="left">2</td>
</tr>
<tr class="odd">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody></table>
<p><strong>Variable type: character</strong></p>
<table>
<thead><tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">min</th>
<th align="right">max</th>
<th align="right">empty</th>
<th align="right">n_unique</th>
<th align="right">whitespace</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">state</td>
<td align="right">110</td>
<td align="right">1.00</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">50</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">gender</td>
<td align="right">141</td>
<td align="right">1.00</td>
<td align="right">4</td>
<td align="right">6</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">race</td>
<td align="right">287</td>
<td align="right">0.99</td>
<td align="right">5</td>
<td align="right">15</td>
<td align="right">0</td>
<td align="right">6</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">pres_appr</td>
<td align="right">9646</td>
<td align="right">0.75</td>
<td align="right">6</td>
<td align="right">10</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">voted</td>
<td align="right">4078</td>
<td align="right">0.89</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: factor</strong></p>
<table>
<thead><tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">ordered</th>
<th align="right">n_unique</th>
<th align="left">top_counts</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">income</td>
<td align="right">2517</td>
<td align="right">0.93</td>
<td align="left">TRUE</td>
<td align="right">5</td>
<td align="left">34 : 11740, 68 : 9974, 0 -: 6300, 17 : 6213</td>
</tr>
<tr class="even">
<td align="left">age</td>
<td align="right">450</td>
<td align="right">0.99</td>
<td align="left">TRUE</td>
<td align="right">7</td>
<td align="left">25 : 7669, 35 : 7342, 45 : 6545, 55 : 6021</td>
</tr>
<tr class="odd">
<td align="left">education</td>
<td align="right">397</td>
<td align="right">0.99</td>
<td align="left">TRUE</td>
<td align="right">7</td>
<td align="left">Hig: 9269, Som: 8540, Col: 5540, Som: 4688</td>
</tr>
<tr class="even">
<td align="left">region</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="left">FALSE</td>
<td align="right">4</td>
<td align="left">Sou: 13680, Mid: 10072, Wes: 7428, Nor: 7378</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead><tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">year</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">1989.40</td>
<td align="right">20.5</td>
<td align="right">1952</td>
<td align="right">1972</td>
<td align="right">1992</td>
<td align="right">2012</td>
<td align="right">2016</td>
<td align="left">▃▃▃▃▇</td>
</tr>
<tr class="even">
<td align="left">ideology</td>
<td align="right">619</td>
<td align="right">0.98</td>
<td align="right">-0.38</td>
<td align="right">2.1</td>
<td align="right">-3</td>
<td align="right">-2</td>
<td align="right">-1</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="left">▇▂▂▂▅</td>
</tr>
</tbody>
</table>
<p>There are three data types: factors, characters, and numeric. <code>income</code>, <code>age</code>, and <code>education</code> are ordered factors. This means that each factor level has a relationship with the others. In the <code>age</code> variable, for example, <code>25 - 34</code> is bigger <code>17 - 24</code> and smaller than <code>35 - 44</code>. But there is no sense of <em>how much</em> bigger or smaller it is. Ordered factors can have weird effects in certain models, so we need to be wary.</p>
<p>Note that all of the variables are incomplete, meaning they contain <code>NA</code> values. While there are methods to impute missing data, we will simply remove these values for now.</p>
<div class="sourceCode" id="cb1092"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1092-1"><a href="continuous-response.html#cb1092-1"></a>ch11 &lt;-<span class="st"> </span>nes <span class="op">%&gt;%</span></span>
<span id="cb1092-2"><a href="continuous-response.html#cb1092-2"></a><span class="st">  </span><span class="kw">select</span>(year, gender, race, income, age, education, ideology, region) <span class="op">%&gt;%</span></span>
<span id="cb1092-3"><a href="continuous-response.html#cb1092-3"></a><span class="st">  </span><span class="kw">drop_na</span>()</span></code></pre></div>
<!-- DK: What should I do with ordered factors? Change them here? Change them in nes itself? If I leave them, will our various models be able to do something with them? Perhaps I will need to use a step_* to fix? Or maybe step_dummy() takes care of that? -->
<p>The first step in a proper data science project is to split our data set into training and testing samples, and then to create cross-validations from the training data.</p>
<div class="sourceCode" id="cb1093"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1093-1"><a href="continuous-response.html#cb1093-1"></a><span class="kw">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb1093-2"><a href="continuous-response.html#cb1093-2"></a>ch11_split &lt;-<span class="st"> </span><span class="kw">initial_split</span>(ch11, <span class="dt">prob =</span> <span class="fl">0.80</span>)</span>
<span id="cb1093-3"><a href="continuous-response.html#cb1093-3"></a>ch11_train &lt;-<span class="st"> </span><span class="kw">training</span>(ch11_split)</span>
<span id="cb1093-4"><a href="continuous-response.html#cb1093-4"></a>ch11_test  &lt;-<span class="st"> </span><span class="kw">testing</span>(ch11_split)</span>
<span id="cb1093-5"><a href="continuous-response.html#cb1093-5"></a>ch11_folds &lt;-<span class="st"> </span><span class="kw">vfold_cv</span>(ch11_train, <span class="dt">v =</span> <span class="dv">10</span>)</span></code></pre></div>
<p>We can now explore three different models for this problem: a traditional linear model, a Bayesian linear model, and a neural network.</p>
<!-- DK: Could give a brief review of each model at the start, perhaps even fit it on the whole data set and discuss what you see. Or maybe do that all at once, in this section here. -->
</div>
<div id="linear-model" class="section level2">
<h2>
<span class="header-section-number">11.2</span> Linear model</h2>
<p>Create the workflow object with the model engine.</p>
<div class="sourceCode" id="cb1094"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1094-1"><a href="continuous-response.html#cb1094-1"></a>lm_wfl &lt;-<span class="st"> </span><span class="kw">workflow</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1094-2"><a href="continuous-response.html#cb1094-2"></a><span class="st">  </span><span class="kw">add_model</span>(<span class="kw">linear_reg</span>() <span class="op">%&gt;%</span></span>
<span id="cb1094-3"><a href="continuous-response.html#cb1094-3"></a><span class="st">            </span><span class="kw">set_engine</span>(<span class="st">"lm"</span>) <span class="op">%&gt;%</span></span>
<span id="cb1094-4"><a href="continuous-response.html#cb1094-4"></a><span class="st">            </span><span class="kw">set_mode</span>(<span class="st">"regression"</span>))</span></code></pre></div>
<p>The <strong><em>parsnip</em></strong> package allows us to create an engine that can run this linear regression model easily and repeatedly. <code>linear_reg()</code> tells the engine that this is a linear regression. <code>set_engine("lm")</code> tells the engine to use the <code>lm()</code> function. <code>set_mode()</code> has two options: “regression” and “classification.” Since our left-hand variable is continuous, we will set it to “regression.” If it were categorical, we would set the mode to “classification”. The default is “regression,” so the <code>set_mode()</code> command has no effect in this case.</p>
<p>Add a recipe.</p>
<div class="sourceCode" id="cb1095"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1095-1"><a href="continuous-response.html#cb1095-1"></a>lm_wfl &lt;-<span class="st"> </span><span class="kw">workflow</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1095-2"><a href="continuous-response.html#cb1095-2"></a><span class="st">  </span><span class="kw">add_model</span>(<span class="kw">linear_reg</span>() <span class="op">%&gt;%</span></span>
<span id="cb1095-3"><a href="continuous-response.html#cb1095-3"></a><span class="st">            </span><span class="kw">set_engine</span>(<span class="st">"lm"</span>) <span class="op">%&gt;%</span></span>
<span id="cb1095-4"><a href="continuous-response.html#cb1095-4"></a><span class="st">            </span><span class="kw">set_mode</span>(<span class="st">"regression"</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1095-5"><a href="continuous-response.html#cb1095-5"></a><span class="st">  </span><span class="kw">add_recipe</span>(<span class="kw">recipe</span>(ideology <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>race <span class="op">+</span><span class="st"> </span>region <span class="op">+</span><span class="st"> </span></span>
<span id="cb1095-6"><a href="continuous-response.html#cb1095-6"></a><span class="st">                      </span>income <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>education,</span>
<span id="cb1095-7"><a href="continuous-response.html#cb1095-7"></a>                    <span class="dt">data =</span> ch11_train) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1095-8"><a href="continuous-response.html#cb1095-8"></a><span class="st">             </span><span class="kw">step_dummy</span>(<span class="kw">all_nominal</span>())</span>
<span id="cb1095-9"><a href="continuous-response.html#cb1095-9"></a>             ) </span></code></pre></div>
<!-- DK: Why don't I need step_dummy(all_nominal())? Especially since age is an ordered factor. How does lm magically handle this? -->
<p>The required parts of the recipe are the model and a data set. The data set does not really matter that much since we are not really using it for anything at this stage of the process. Its purpose is to ensure that tidymodels can process the recipe. To do so, it needs to know if, for example, <code>gender</code> is character or factor or numeric. You would get the same result whether you used <code>ch_11</code>, <code>ch_11_train</code> or <code>ch_11_test</code> as the value for <code>data</code>. But, it is a good habit to never use the test data until the very end, even if doing so is harmless.</p>
<p>The formula portion of the recipe will, depending in the model, look a lot like the formulas which you have passed to <code>stan_glm()</code>. But, in tidymodels, we are not allowed to do any mathematical operations in the recipe itself, beyond addition. Any such operations need to be placed in <code>step_*</code> functions. Recall how, in Chapter <a href="model-choice.html#model-choice">10</a>, we used <code>step_interact()</code> to add an interaction term. Figuring out which <code>step_*</code> functions we want to use and why is the hardest part of tidymodels.</p>
<p>Examine performance on the cross-validation samples.</p>
<div class="sourceCode" id="cb1096"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1096-1"><a href="continuous-response.html#cb1096-1"></a>lm_metrics &lt;-<span class="st"> </span>lm_wfl <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1096-2"><a href="continuous-response.html#cb1096-2"></a><span class="st">  </span><span class="kw">fit_resamples</span>(<span class="dt">resamples =</span> ch11_folds) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1096-3"><a href="continuous-response.html#cb1096-3"></a><span class="st">  </span><span class="kw">collect_metrics</span>()</span>
<span id="cb1096-4"><a href="continuous-response.html#cb1096-4"></a></span>
<span id="cb1096-5"><a href="continuous-response.html#cb1096-5"></a>lm_metrics</span></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   .metric .estimator  mean     n std_err
##   &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
## 1 rmse    standard   1.98     10 0.00632
## 2 rsq     standard   0.102    10 0.00401</code></pre>
<p>Check the predictions against the actual values for the training data.</p>
<div class="sourceCode" id="cb1098"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1098-1"><a href="continuous-response.html#cb1098-1"></a>lm_wfl <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1098-2"><a href="continuous-response.html#cb1098-2"></a><span class="st">  </span><span class="kw">fit</span>(<span class="dt">data =</span> ch11_train) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1098-3"><a href="continuous-response.html#cb1098-3"></a><span class="st">  </span><span class="kw">predict</span>(<span class="dt">new_data =</span> ch11_train) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1098-4"><a href="continuous-response.html#cb1098-4"></a><span class="st">  </span><span class="kw">bind_cols</span>(ch11_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(ideology)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1098-5"><a href="continuous-response.html#cb1098-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">y =</span> ideology, <span class="dt">x =</span> <span class="st">`</span><span class="dt">.pred</span><span class="st">`</span>)) <span class="op">+</span></span>
<span id="cb1098-6"><a href="continuous-response.html#cb1098-6"></a><span class="st">    </span><span class="kw">geom_jitter</span>(<span class="dt">height =</span> <span class="fl">0.2</span>, <span class="dt">alpha =</span> <span class="fl">0.01</span>) <span class="op">+</span></span>
<span id="cb1098-7"><a href="continuous-response.html#cb1098-7"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">"Predicting Ideology"</span>,</span>
<span id="cb1098-8"><a href="continuous-response.html#cb1098-8"></a>         <span class="dt">subtitle =</span> <span class="st">"Using a linear model with demographic predictors"</span>,</span>
<span id="cb1098-9"><a href="continuous-response.html#cb1098-9"></a>         <span class="dt">x =</span> <span class="st">"Predicted Ideology"</span>,</span>
<span id="cb1098-10"><a href="continuous-response.html#cb1098-10"></a>         <span class="dt">y =</span> <span class="st">"Ideology"</span>,</span>
<span id="cb1098-11"><a href="continuous-response.html#cb1098-11"></a>         <span class="dt">caption =</span> <span class="st">"Source: CCES"</span>) </span></code></pre></div>
<p><img src="book_temp_files/figure-html/unnamed-chunk-850-1.png" width="672"></p>
<p>Is this result good or bad? Depends on your point of view! If we predict that someone’s ideology is 0, then we don’t know that much about their ideology. It could be an anywhere from -3 (strong Democrat) to +3 (strong Republican).</p>
<!-- DK: We need more instruction. But do we need it here or in an appendix? We should look at this plot, change the workflow, look at the plot again, and so on. -->
</div>
<div id="bayesian-linear-model" class="section level2">
<h2>
<span class="header-section-number">11.3</span> Bayesian linear model</h2>
<p>Create the workflow object with the model engine. Note that every part is the same as the linear model we just completed <em>except</em> that the required engine is “stan”.</p>
<div class="sourceCode" id="cb1099"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1099-1"><a href="continuous-response.html#cb1099-1"></a>stan_wfl &lt;-<span class="st"> </span><span class="kw">workflow</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1099-2"><a href="continuous-response.html#cb1099-2"></a><span class="st">  </span><span class="kw">add_model</span>(<span class="kw">linear_reg</span>() <span class="op">%&gt;%</span></span>
<span id="cb1099-3"><a href="continuous-response.html#cb1099-3"></a><span class="st">            </span><span class="kw">set_engine</span>(<span class="st">"stan"</span>) <span class="op">%&gt;%</span></span>
<span id="cb1099-4"><a href="continuous-response.html#cb1099-4"></a><span class="st">            </span><span class="kw">set_mode</span>(<span class="st">"regression"</span>))</span></code></pre></div>
<p>Add a recipe.</p>
<div class="sourceCode" id="cb1100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1100-1"><a href="continuous-response.html#cb1100-1"></a>stan_wfl &lt;-<span class="st"> </span><span class="kw">workflow</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1100-2"><a href="continuous-response.html#cb1100-2"></a><span class="st">  </span><span class="kw">add_model</span>(<span class="kw">linear_reg</span>() <span class="op">%&gt;%</span></span>
<span id="cb1100-3"><a href="continuous-response.html#cb1100-3"></a><span class="st">            </span><span class="kw">set_engine</span>(<span class="st">"stan"</span>) <span class="op">%&gt;%</span></span>
<span id="cb1100-4"><a href="continuous-response.html#cb1100-4"></a><span class="st">            </span><span class="kw">set_mode</span>(<span class="st">"regression"</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1100-5"><a href="continuous-response.html#cb1100-5"></a><span class="st">  </span><span class="kw">add_recipe</span>(<span class="kw">recipe</span>(ideology <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>race <span class="op">+</span><span class="st"> </span>region <span class="op">+</span><span class="st"> </span></span>
<span id="cb1100-6"><a href="continuous-response.html#cb1100-6"></a><span class="st">                      </span>income <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>education,</span>
<span id="cb1100-7"><a href="continuous-response.html#cb1100-7"></a>                    <span class="dt">data =</span> ch11_train) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1100-8"><a href="continuous-response.html#cb1100-8"></a><span class="st">             </span><span class="kw">step_dummy</span>(<span class="kw">all_nominal</span>())</span>
<span id="cb1100-9"><a href="continuous-response.html#cb1100-9"></a>             ) </span></code></pre></div>
<p>Examine performance on the cross-validation samples.</p>
<!-- DK: Unlike with lm() above, we get different answers depending on whether or not we use step_dummy(all_nominal()). But the differences are very small (4th decimal, at least in the collected metrics), so let's ignore it for now. -->
<div class="sourceCode" id="cb1101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1101-1"><a href="continuous-response.html#cb1101-1"></a>stan_metrics &lt;-<span class="st"> </span>stan_wfl <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1101-2"><a href="continuous-response.html#cb1101-2"></a><span class="st">  </span><span class="kw">fit_resamples</span>(<span class="dt">resamples =</span> ch11_folds) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1101-3"><a href="continuous-response.html#cb1101-3"></a><span class="st">  </span><span class="kw">collect_metrics</span>()</span>
<span id="cb1101-4"><a href="continuous-response.html#cb1101-4"></a></span>
<span id="cb1101-5"><a href="continuous-response.html#cb1101-5"></a>stan_metrics</span></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   .metric .estimator  mean     n std_err
##   &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
## 1 rmse    standard   1.98     10 0.00632
## 2 rsq     standard   0.102    10 0.00401</code></pre>
<p>Check the predictions against the actual values.</p>
<div class="sourceCode" id="cb1103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1103-1"><a href="continuous-response.html#cb1103-1"></a>stan_wfl <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1103-2"><a href="continuous-response.html#cb1103-2"></a><span class="st">  </span><span class="kw">fit</span>(<span class="dt">data =</span> ch11_train) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1103-3"><a href="continuous-response.html#cb1103-3"></a><span class="st">  </span><span class="kw">predict</span>(<span class="dt">new_data =</span> ch11_train) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1103-4"><a href="continuous-response.html#cb1103-4"></a><span class="st">  </span><span class="kw">bind_cols</span>(ch11_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(ideology)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1103-5"><a href="continuous-response.html#cb1103-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">y =</span> ideology, <span class="dt">x =</span> <span class="st">`</span><span class="dt">.pred</span><span class="st">`</span>)) <span class="op">+</span></span>
<span id="cb1103-6"><a href="continuous-response.html#cb1103-6"></a><span class="st">    </span><span class="kw">geom_jitter</span>(<span class="dt">height =</span> <span class="fl">0.2</span>, <span class="dt">alpha =</span> <span class="fl">0.01</span>) <span class="op">+</span></span>
<span id="cb1103-7"><a href="continuous-response.html#cb1103-7"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">"Predicting Ideology"</span>,</span>
<span id="cb1103-8"><a href="continuous-response.html#cb1103-8"></a>         <span class="dt">subtitle =</span> <span class="st">"Using a Bayesian linear model with demographic predictors"</span>,</span>
<span id="cb1103-9"><a href="continuous-response.html#cb1103-9"></a>         <span class="dt">x =</span> <span class="st">"Predicted Ideology"</span>,</span>
<span id="cb1103-10"><a href="continuous-response.html#cb1103-10"></a>         <span class="dt">y =</span> <span class="st">"Ideology"</span>,</span>
<span id="cb1103-11"><a href="continuous-response.html#cb1103-11"></a>         <span class="dt">caption =</span> <span class="st">"Source: CCES"</span>)</span></code></pre></div>
<p><img src="book_temp_files/figure-html/unnamed-chunk-854-1.png" width="672"></p>
<!-- DK: Add more discussion. Perhaps discuss the posterior probability distribution for true ideology given predicted ideology. Note that the model never predicts ideology 2 or 3. Is that good or bad? -->
</div>
<div id="neural-networks" class="section level2">
<h2>
<span class="header-section-number">11.4</span> Neural networks</h2>
<!-- DK: Switch this to neural network. Make it work better than use it with temperance. Show how you can't just use coefficients with serious models. Save random forest for chapter 12. -->
<p>Neural networks are a powerful “non-parametric” approach to forecasting. Recall that, in both <code>lm()</code> and <code>stan_glm()</code> models, there are specified parameters which we are trying to estimate. We “care” about these parameters because they often correspond to real world entities, like the average treatment effect.</p>
<p>With non-parametric models, there are no parameters which we care about. (That is a loose and not-quite-correct definition.) Instead, the model is a “black box” into which predictors are fed and from which predicted outcomes emerge.</p>
<p>Create the workflow object with the model engine.</p>
<div class="sourceCode" id="cb1104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1104-1"><a href="continuous-response.html#cb1104-1"></a>nn_wfl &lt;-<span class="st"> </span><span class="kw">workflow</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1104-2"><a href="continuous-response.html#cb1104-2"></a><span class="st">  </span><span class="kw">add_model</span>(<span class="kw">mlp</span>(<span class="dt">epochs =</span> <span class="dv">100</span>, </span>
<span id="cb1104-3"><a href="continuous-response.html#cb1104-3"></a>                <span class="dt">hidden_units =</span> <span class="dv">5</span>, </span>
<span id="cb1104-4"><a href="continuous-response.html#cb1104-4"></a>                <span class="dt">dropout =</span> <span class="fl">0.1</span>) <span class="op">%&gt;%</span></span>
<span id="cb1104-5"><a href="continuous-response.html#cb1104-5"></a><span class="st">            </span><span class="kw">set_engine</span>(<span class="st">"keras"</span>, <span class="dt">verbose =</span> <span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1104-6"><a href="continuous-response.html#cb1104-6"></a><span class="st">            </span><span class="kw">set_mode</span>(<span class="st">"regression"</span>))</span></code></pre></div>
<p>The next step is to add a recipe.</p>
<div class="sourceCode" id="cb1105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1105-1"><a href="continuous-response.html#cb1105-1"></a>nn_wfl &lt;-<span class="st"> </span><span class="kw">workflow</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1105-2"><a href="continuous-response.html#cb1105-2"></a><span class="st">  </span><span class="kw">add_model</span>(<span class="kw">mlp</span>(<span class="dt">epochs =</span> <span class="dv">100</span>, </span>
<span id="cb1105-3"><a href="continuous-response.html#cb1105-3"></a>                <span class="dt">hidden_units =</span> <span class="dv">5</span>, </span>
<span id="cb1105-4"><a href="continuous-response.html#cb1105-4"></a>                <span class="dt">dropout =</span> <span class="fl">0.1</span>) <span class="op">%&gt;%</span></span>
<span id="cb1105-5"><a href="continuous-response.html#cb1105-5"></a><span class="st">            </span><span class="kw">set_engine</span>(<span class="st">"nnet"</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1105-6"><a href="continuous-response.html#cb1105-6"></a><span class="st">            </span><span class="kw">set_mode</span>(<span class="st">"regression"</span>)) <span class="op">%&gt;%</span></span>
<span id="cb1105-7"><a href="continuous-response.html#cb1105-7"></a><span class="st">  </span><span class="kw">add_recipe</span>(<span class="kw">recipe</span>(ideology <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>race <span class="op">+</span><span class="st"> </span>region <span class="op">+</span><span class="st"> </span></span>
<span id="cb1105-8"><a href="continuous-response.html#cb1105-8"></a><span class="st">                      </span>income <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>education,</span>
<span id="cb1105-9"><a href="continuous-response.html#cb1105-9"></a>                    <span class="dt">data =</span> ch11_train) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1105-10"><a href="continuous-response.html#cb1105-10"></a><span class="st">             </span><span class="kw">step_dummy</span>(<span class="kw">all_nominal</span>())</span>
<span id="cb1105-11"><a href="continuous-response.html#cb1105-11"></a>             )</span></code></pre></div>
<p>Note that there are improvements we could make to this model. As a rule of thumb, whenever using non-parametric models, you should use <code>step_normalize(all_numeric())</code> which, as you might guess, normalizes all numeric variables.</p>
<p>Examine performance on the cross-validation samples.</p>
<div class="sourceCode" id="cb1106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1106-1"><a href="continuous-response.html#cb1106-1"></a>nn_metrics &lt;-<span class="st"> </span>nn_wfl <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1106-2"><a href="continuous-response.html#cb1106-2"></a><span class="st">  </span><span class="kw">fit_resamples</span>(<span class="dt">resamples =</span> ch11_folds) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1106-3"><a href="continuous-response.html#cb1106-3"></a><span class="st">  </span><span class="kw">collect_metrics</span>()</span>
<span id="cb1106-4"><a href="continuous-response.html#cb1106-4"></a></span>
<span id="cb1106-5"><a href="continuous-response.html#cb1106-5"></a>nn_metrics </span></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   .metric .estimator  mean     n std_err
##   &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
## 1 rmse    standard   1.97     10 0.00575
## 2 rsq     standard   0.111    10 0.00422</code></pre>
<p>Check the predictions against the actual values.</p>
<div class="sourceCode" id="cb1108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1108-1"><a href="continuous-response.html#cb1108-1"></a>nn_wfl <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1108-2"><a href="continuous-response.html#cb1108-2"></a><span class="st">  </span><span class="kw">fit</span>(<span class="dt">data =</span> ch11_train) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1108-3"><a href="continuous-response.html#cb1108-3"></a><span class="st">  </span><span class="kw">predict</span>(<span class="dt">new_data =</span> ch11_train) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1108-4"><a href="continuous-response.html#cb1108-4"></a><span class="st">  </span><span class="kw">bind_cols</span>(ch11_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(ideology)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1108-5"><a href="continuous-response.html#cb1108-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">y =</span> ideology, <span class="dt">x =</span> <span class="st">`</span><span class="dt">.pred</span><span class="st">`</span>)) <span class="op">+</span></span>
<span id="cb1108-6"><a href="continuous-response.html#cb1108-6"></a><span class="st">    </span><span class="kw">geom_jitter</span>(<span class="dt">width =</span> <span class="fl">0.2</span>, <span class="dt">alpha =</span> <span class="fl">0.01</span>) <span class="op">+</span></span>
<span id="cb1108-7"><a href="continuous-response.html#cb1108-7"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">"Predicting Ideology"</span>,</span>
<span id="cb1108-8"><a href="continuous-response.html#cb1108-8"></a>         <span class="dt">subtitle =</span> <span class="st">"Using a neural network with demographic predictors"</span>,</span>
<span id="cb1108-9"><a href="continuous-response.html#cb1108-9"></a>         <span class="dt">x =</span> <span class="st">"Predicted Ideology"</span>,</span>
<span id="cb1108-10"><a href="continuous-response.html#cb1108-10"></a>         <span class="dt">y =</span> <span class="st">"Ideology"</span>,</span>
<span id="cb1108-11"><a href="continuous-response.html#cb1108-11"></a>         <span class="dt">caption =</span> <span class="st">"Source: CCES"</span>)</span></code></pre></div>
<p><img src="book_temp_files/figure-html/unnamed-chunk-858-1.png" width="672"></p>
<!-- DK: The last two graphs are different. Discuss! See how well this model does with low predictions. Every time predicted ideology is below -2.5, the true ideology is -3. The linear models are much more likely to make mistakes when predicting very negative ideology values. -->
</div>
<div id="model-comparison" class="section level2">
<h2>
<span class="header-section-number">11.5</span> Model comparison</h2>
<p>The most common method for deciding which model to choose is to look at which one does the best predicting out of sample. As a reminder, here is a summary of how well our three different models performed.</p>
<div class="sourceCode" id="cb1109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1109-1"><a href="continuous-response.html#cb1109-1"></a><span class="kw">tibble</span>(<span class="dt">model =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">"Linear Model"</span>, </span>
<span id="cb1109-2"><a href="continuous-response.html#cb1109-2"></a>                     <span class="st">"Bayesian Linear Model"</span>, </span>
<span id="cb1109-3"><a href="continuous-response.html#cb1109-3"></a>                     <span class="st">"Neural Network"</span>), <span class="dt">each =</span> <span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1109-4"><a href="continuous-response.html#cb1109-4"></a><span class="st">  </span><span class="kw">bind_cols</span>(<span class="kw">bind_rows</span>(lm_metrics, stan_metrics, nn_metrics)) </span></code></pre></div>
<pre><code>## # A tibble: 6 x 6
##   model                 .metric .estimator  mean     n std_err
##   &lt;chr&gt;                 &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
## 1 Linear Model          rmse    standard   1.98     10 0.00632
## 2 Linear Model          rsq     standard   0.102    10 0.00401
## 3 Bayesian Linear Model rmse    standard   1.98     10 0.00632
## 4 Bayesian Linear Model rsq     standard   0.102    10 0.00401
## 5 Neural Network        rmse    standard   1.97     10 0.00575
## 6 Neural Network        rsq     standard   0.111    10 0.00422</code></pre>
<p>The results for the neural network model are slightly better than those for either linear model.</p>
</div>
<div id="cardinal-virtues-1" class="section level2">
<h2>
<span class="header-section-number">11.6</span> Cardinal virtues</h2>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">-->
<img src="other/images/Wisdom.jpg" alt=" " width="1280"><!--
<p class="caption marginnote">--><!--</p>--><!--</div>--></span>
</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">-->
<img src="other/images/Justice.jpg" alt=" " width="960"><!--
<p class="caption marginnote">--><!--</p>--><!--</div>--></span>
</p>
<p>The lessons of the Cardinal Virtues continue to apply.</p>
<p><em>Wisdom</em> asks us if the problem we are trying to solve is “close enough” to the data we have that we might fairly consider both to come from the same population. Using US data from 2016 to create a model of ideology for the US in 2020 is reasonable. Using US data from 2016 to create a model of ideology for Brazil in 1966 is less so.</p>
<p><em>Justice</em> instructs us to distinguish causal from predictive models. This mode is clearly predictive. None of our demographic covariates were randomly assigned. It is possible to manipulate a variable like income, and therefore to consider (at least) two potential outcomes for a given person: ideology if rich and ideology if poor. But, although a causal model for the effect of income on ideology is at least conceivable, it is highly unlikely that such a model would provide a good estimate of the causal effect because income was not assigned randomly. Without random assignment, estimate causal effects is very, very difficult. <em>Regressions and Other Stories</em> by Andrew Gelman, Jennifer Hill, and Aki Vehtari is a good introduction.</p>
<p>Recall that all we care about in a predictive model is forecasting some value <span class="math inline">\(y_i\)</span> given that we know <span class="math inline">\(x_{i_1}, x_{i_2}, ... x_{i_n}\)</span>. The <span class="math inline">\(y_i\)</span> in our case is <code>ideology</code>. The <span class="math inline">\(x_{i_1}, x_{i_2}, ... x_{i_n}\)</span> are certain known variables, such as <code>state</code>, <code>age</code>, and <code>income</code>, among others. <span class="math inline">\(\beta\)</span> stands the list of unknown parameters which must be estimated.</p>
<p>The following equation calculates the <code>ideology</code> of the <em>i</em>th respondent, <span class="math inline">\(y_i\)</span>, as a function of the data and the unknown parameters.</p>
<p><span class="math display">\[y_i = f(x_{i_1}, x_{i_2}, ..., \beta)\]</span></p>
<p>Keep in mind that our goal is to create the best possible model to predict someone’s ideology given a number of demographic variables. That is to say, we plan on using our model on out-of-sample data. Cross validation is the method we will use to forecast how well the model will work on this unseen data.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">-->
<img src="other/images/Courage.jpg" alt=" " width="1024"><!--
<p class="caption marginnote">--><!--</p>--><!--</div>--></span>
</p>
<p><em>Courage</em> helps us to fit the models, as we have above, and then to select the one we want to use. We should only favor more complex models (or formulas) if the additional complexity is <em>warranted</em>. This is a philosophical principle known as “Occam’s Razor.” It states that, “all other things being equal, simpler solutions are more likely to be correct than complex ones.” When viewed in a modeling framework, Occam’s Razor can be restated as, “all other things being equal, simpler models are to be preferred over complex ones.” In other words, we should only favor the more complex model/formula if the additional complexity makes the model meaningfully better.</p>
<p>Is the neural network model meaningfully better than the linear models? Perhaps. Average RMSE is lower but, given the standard error associated with that measure, it is close call. Let’s use the neural network model.</p>
<!-- Time to make up some imaginary people. Let's say we have four individuals whose ideology in 2016 we wanted to predict. We can create a tibble with the values of their demographic information, like so: -->
<!-- Just because you have a variable in this training data today, does not mean you are going to get it in your production data tomorrow. -->
<!-- DK: Do these have to be factors? Or will characters work as well, like they do with posterior_predict? -->
<!-- ```{r} -->
<!-- new_people <- tibble("name" = c("Alice", "Betty", "Chelsea", "Danielle"), -->
<!--                      "region" = as.factor(c("Midwest", "Northeast", "South", "West")), -->
<!--                      "gender" = as.factor(c("Female", "Female", "Female", "Female")), -->
<!--                      "income" = as.factor(c("34 - 67", "34 - 67", "34 - 67", "34 - 67")), -->
<!--                      "age" = c("17 - 24", "17 - 24", "17 - 24", "17 - 24"), -->
<!--                      "education" = c("College", "College", "College", "College"), -->
<!--                      "race" = c("White", "White", "White", "White")) -->
<!-- ``` -->
<!-- Now, let's predict each new person's ideology using the linear regression model we just created. -->
<!-- ```{r message=FALSE} -->
<!-- lm_model %>% -->
<!--   fit(full_form, data = ch11_train) %>% -->
<!--   predict(new_data = new_people) %>% -->
<!--   bind_cols(new_people) %>% -->
<!--   rename("ideology" = ".pred") -->
<!-- ``` -->
<p>
<span class="marginnote shownote">
<!--
<div class="figure">-->
<img src="other/images/Temperance.jpg" alt=" " width="960"><!--
<p class="caption marginnote">--><!--</p>--><!--</div>--></span>
</p>
<p><em>Temperance</em> reminds us to be suspicious of all models, especially our own. The world is always changing. Our models will rarely work as well in the future as they have using data from the past.</p>
<!-- DK: Use a plot like this one: https://www.tidymodels.org/start/models/ -->
</div>
<div id="summary-1" class="section level2">
<h2>
<span class="header-section-number">11.7</span> Summary</h2>
<p>The purpose of this chapter way to practice using tidymodels tools for model selection. The most important measure of model quality is how well the model does on out-of-sample data. Cross validation is only one of many ways to estimate that performance, but it is probably the most popular. For details on other approaches, read <a href="https://www.tmwr.org/resampling.html">Chapter 10</a> of <em>Tidy Modeling with R</em> by Max Kuhn and Julia Silge.</p>

<!-- DK: Sure would be nice to do one mult-category model. Once we get rid of all the logistic regression stuff, we have some extra space/time. -->
</div>
</div></body></html>

<p style="text-align: center;">
<a href="model-choice.html"><button class="btn btn-default">Previous</button></a>
<a href="discrete-response.html"><button class="btn btn-default">Next</button></a>
</p>
<p class="build-date">Page built: 
2020-11-12
</p>
</div>
</div>



</body>
</html>
