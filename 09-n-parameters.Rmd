---
output_yaml:
  - _output.yml
---

# N Parameters {#n-parameters}


*This chapter is a draft.* Come back in a few weeks for a better version.


<!-- Make the plots just a bit nicer, with labels and whatnot. -->

<!-- Key issue: Do we go through the math and preceptor table for each model we are considering within Justice? If so, do we need to do that for all the models, before showing the code for the first model in the Courage section. Or, for each model, do we do math, (maybe) preceptor table, code and interpretation? That seems much better! So, we could do Wisdom, then Justice/Courage, then Temperance. -->

<!-- Justice: each model discussion begins with Justice, which includes a Preceptor Table --- note how this changes for each model, because the Preceptor Table only needs columns for the covariates in the model, and only needs outcome columns for the outcomes you care about --- and then provides the math of the situation, which is also different each time.  A Preceptor Table has the rows and columns such that, if there are no missing values, answering your question is trivial. I guess you might not have to give the Preceptor Table and the math every single time. But you do need to describe how they would differ from the last example. -->

<!-- Courage: Then, we have Courage, which means run the code and interpret it. In other words, each model includes a discussion of Justice and Courage, labeled as such. -->

<!-- Temperance: After you come to your final model, it is time for a discussion of Temperance: All the reasons why you should be careful about what you do with the model in the future. This section includes the use of posterior_predict(). -->


<!-- 1) EDA of `shaming`. I think that hh_size is a good variable to check for interactions with, especially with Control. Create a new variable called `solo` which is TRUE if the `hh_size` is equal to 1 and FALSE otherwise. In other words, does the state of living alone tell us anything? We will interact this term with treatment in our model. It is cool that the p value for the interaction of solo with Self is 0.06. A perfect example for the evils of testing!  -->



<!-- 2) `primary_06` as a function of `treatment`, `gender`, `solo`, `age` and (some of) their interactions. We will build up this model step-by-step, very similar to how we explored the effect of treatment in chapter 8. But we go deeper because  we are learning about interactions. Note that this situation is different from Chapter 8 in that fitted values and predicted values are not the same thing! The fitted value, for a combination of values for treatment and solo, is something 0.30, meaning that 30% of the people in this bucket votes. But the predicted value must be 0 or 1. Either you voted or you didn't. This example is clearly causal and so you need a Rubin Table with 5 potential outcome columns. The key difference in this chapter is that we are using lots of right hand side variables, both continuous and discrete. -->


Having created models with one parameter in Chapter \@ref(one-parameter), two parameters in Chapter \@ref(two-parameters) and three parameters in Chapter \@ref(three-parameters), you are now ready to make the jump to $N$ parameters. 

In this chapter, we will consider models with multiple parameters and the complexities that arise from these additions. 


## EDA of `governors`

Begin by loading the packages which we need.

```{r, message=FALSE}
library(PPBDS.data)
library(skimr)
library(broom.mixed)
library(rstanarm)
library(tidyverse)
```

<!-- Talk about the data, as we usual do. Lots of interesting things. Explain how we only have data for people who are already dead. That is an interesting restriction, and effects the Preceptor Table in interesting ways. Make sure to mention all the variables we end up keeping below. Finish with some graphics which show how various things are related to our lefthand side variable: alive_post. -->

We will start off by using a subset of the `governors` data set from the **PPBDS.data** package. This data set looks at the lifespans of U.S. politicians from 1945 to 2012. It comes from the paper "Longevity Returns to Political Office" by Barfort, Klemmensen & Larsen (2019), and aims to find out whether winning an election influences the lifespan of candidates for governor.

Let's explore the variables and observations contained within this data set by performing an exploratory data analysis. 

```{r}
glimpse(governors)
```

There are 11 variables and 1,092 observations. In this chapter, we will only be looking at the variables `last_name`, `year`, `state`, `sex`, `status`, `alive_post`, and `alive_pre`. We will also create a new variable called `won` that is `TRUE` when the win margin is greater than 0, and `FALSE` if not.

```{r}
ch9_gov <- governors %>% 
  mutate(won = ifelse(win_margin > 0, TRUE, FALSE)) %>% 
  select(last_name, year, state, sex, status, won, alive_post, alive_pre)
```

There are a few things to note when looking at this data. First, the data set includes the variables `alive_pre` and `alive_post`, which tell us how many days a candidate lived before the election took place and how many days a candidate lived after the election, respectively. Therefore, only politicians who are already deceased are included in this data set. Furthermore, candidates with unknown dates of death were not included. This means that there are only a handful of observations from elections in the last 20 years. Most candidates from that time are still alive and are excluded due to an unknown/yet-to-be-determined value for the column `alive_post`.

Another caveat is that for a given election, only the top two candidates are included in the data set. If a politician did not receive the highest or second-highest number of votes, they are excluded. 

Finally, it is noted that for some observations, only the birth or death year of a candidate could be determined, in which case the date was taken as July 1st of that year.

Let's run `sample_n()`:

```{r}
sample_n(ch9_gov, 10)
```

From this sample, we can see some trends start to appear. For example, we see that `sex` is most often "Male", and status is most often "Challenger" rather than "Incumbent".

Let's summarize the data with `skim()`:

```{r}
skim(ch9_gov)
```

This output groups the variables together by type (character, logical, numeric, etc.). From this, we can see things like the number of unique last names, how many of the observations in our subset won versus how many lost their elections, and the mean number of days before and after a gubernatorial election that a candidate lived. We are also given histograms of the numerical data. In looking at the histogram for `year`, we see that it is skewed right, with half of the observations from election years between 1945 and 1962. This makes sense logically, because we are only looking at deceased candidates, and candidates from more recent elections are more likely to still be alive.

In using this data set, our left-side variable will be `alive_post`. We want to know how the election affected the lifespan of these gubernatorial candidates. Let's look at some graphs and plots showing the relationships between `alive_post` and some of the other variables in our subset.

```{r}
ch9_gov %>%
  ggplot(aes(x = year, y = alive_post)) +
  geom_point()
```

Starting with the relationship between `alive_post` and `year`, we can see that the data is skewed right and that there is a defined line that data points do not exist above. There are no data points in the top right portion of the graph because it is not possible to have run in 2011, lived 20,000 days after the election took place, and still have died before the data set was created. This line represents the most a candidate could have possibly lived - and still have died - to be included the data set. The reason this line is slanted downward is because the maximum value for this scenario is greater in earlier years. That is, those candidates who ran for governor in earlier years could live a longer time after the election and still have died prior to the data set creation, giving them higher `alive_post` values than those who ran for office in later years. 

There are fewer observations in later years because fewer candidates have died. The vast maajority of candidates who ran for office in the 21st century are still alive today and therefore excluded from this data set. 


```{r}
ch9_gov %>%
  ggplot(aes(x = won, y = alive_post)) +
  geom_boxplot()
```

This box plot is interesting in that it takes a direct look at the relationship we are trying to learn more about: whether winning an election influences the lifespan of politicians. 

<!-- Clean up and add more discussion here -->


## Wisdom

```{r echo=FALSE, fig.margin=TRUE, fig.cap="Wisdom"}
knitr::include_graphics("other/images/Wisdom.jpg")
```


## Justice and Courage

```{r echo=FALSE, fig.margin=TRUE, fig.cap="Justice"}
knitr::include_graphics("other/images/Justice.jpg")
```

```{r echo=FALSE, fig.margin=TRUE, fig.cap="Courage"}
knitr::include_graphics("other/images/Courage.jpg")
```

Because we will be going through a series of models in this chapter, it is useful to combine the virtues of Justice and Courage.



<!-- DK: Maybe instead of tables, we should just be showing graphics, using ggdist/tidybayes. -->

Let's explore descriptive, not causal, models which seek to explain longevity post-election.

To begin, let's model candidate lifespan after the election as a function of candidate lifespan prior to the election. The math is fairly simple:

$$ alive.post_i =  \beta_0 + \beta_1 alive.pre_i + \epsilon_i $$

with $\epsilon_i \sim N(0, \sigma^2)$. $alive.post_i$ is the number of days lived after the election for candidate $i$. $\beta_0$ is the "intercept" of the regression, the value of $alive.post_i$ if $alive.pre_i = 0$ . $\beta_1$ is the "coefficient" of  $alive.pre$. Each one day increase in $alive.pre$ is associated with a $\beta_1$ change in $alive.post$. $\epsilon_i$ is the "error term," the difference between the days-lived of candidate $i$ and the average days-lived of all candidates.  $\epsilon_i$ is normally distributed with a mean of 0 and a standard deviation of $\sigma$. There are three unknown parameters, similar to the situation we faced in Chapter \@ref{three-parameters}.

<!-- DK: More discussion. Perhaps a Preceptor Table. -->

We can implement this model with `stan_glm()`. 

<!-- DK: Explain regress and regression. -->

```{r, cache = TRUE}
fit_gov_1 <- stan_glm(data = ch9_gov,
                      formula = alive_post ~ alive_pre,
                      family = gaussian(),
                      refresh = 0)
```

Most of the time, we are only interested in the parameter values.

```{r}
print(fit_gov_1, detail = FALSE)
```

As is almost always the case, $\sigma$ is a nuisance parameter, somethings whose value we are not interested in. This is why `stan_glm()` refers to it as an "auxiliary" parameter.

The posterior distributions of $\beta_0$ (the intercept) and $\beta_1$ (the coefficient of `alive_pre`), on the other hand, are very important. Before looking at the posteriors themselves, let's see what happens when we place the medians into the model:

$$ alive.post_i =  26,524 - 0.9 alive.pre_i + \epsilon_i$$

Consider the intercept. Since our independent variable is `alive_pre`, the intercept is the `alive_post` value when `alive_pre` is zero. Here, we would interpret this intercept as the lifespan of a gubernatorial candidate after the election, if the candidate was alive for zero days prior to the election. 

This is, of course, substantively nonsense. No one runs for office on the day they are born. In the next model, we will explore ways of making the intercept more interpretable. In the meantime, the math is the math. 

Let's continue by discussing the coefficient for `alive_pre`, $\beta_1$. The median of the posterior, -0.9, represents the slope of the model. For every unit increase in our independent variable, our dependent variable will change by this coefficient. Putting this slope definition in terms of our model, this means that for every additional day a candidate is alive before an election, their lifespan after the election will be 0.9 days lower, on average. If we are given the number of days a candidate lived before the election and want to estimate how long they will live for after, we will multiply the days they were alive prior by this beta of -0.9, then subtract that from the intercept. 

This is a descriptive model, not a causal model. Remember our motto from Chapter \@ref(rubin-causal-model): No causation without manipulation. There is no way, for person $i$, to change the days that she has been alive on Election Day. On the day of this election, she is X days old. There is no way to change that. So, there are not two (or more) potential outcomes. Without more than one potential outcome, there can not be a causal effect.

Let's look at the posterior of $\beta_1$, the coefficient of `alive_pre`:

<!-- DK: We should standardize what these plots look like, both in this chapter and throughout the book. -->

```{r}
fit_gov_1 %>% 
  as_tibble() %>% 
  ggplot(aes(alive_pre)) + 
    geom_histogram(bins = 100) +
    labs(title = "Posterior Distribution of the Coefficient of `alive_pre`",
         y = "Probability",
         x = "Coefficient of `alive_pre`")
```

<!-- DK: Add some interpretation. -->


Centering is a tool that is used when the model's intercept does not make logical sense. To center a model, we pick a constant value, usually the mean of the independent variable, and subtract that constant from every value of the independent variable. This changes the zero point for the variable and shifts the model over.

In this example, we want to center the value for `alive_pre`, the independent variable First, we must pick the value that we will center by. Here, we will use the mean of `alive_pre`. Once we find this value, we will subtract it to every `alive_pre` value, creating a new variable called `alive_pre_centered`. We then use `alive_pre_centered` as the indepdent variable to explain `alive_post`.

```{r}
ch9_gov$alive_pre_centered <- ch9_gov$alive_pre - mean(ch9_gov$alive_pre)
```

```{r, cache = TRUE}
fit_gov_1.centered <- stan_glm(data = ch9_gov,
                      formula = alive_post ~ alive_pre_centered,
                      family = gaussian(),
                      refresh = 0)
```

```{r}
print(fit_gov_1.centered, detail = FALSE)
```

In this model, we can see that the intercept has increased while the slope has stayed the same. When we interpret this model, we only have to change the definition of the intercept. Rather than the intercept representing the lifespan of a candidate who was alive for zero days before running for governor, it now represents the post-election lifespan of a gubernatorial candidate who was alive for the mean number of days before running. In this instance, our center value is approximately 18,892, so we will use this value in our interpretation. If a candidate was alive for 18,892 days before running for governor (the mean value in this data set), they are expected to live for 10,309 days after the election, on average. 

Since all values of the predictor variable decreased by the same amount, the model shifted over but the slope of the linear model did not change. In fact, any linear change in the predictor variables has no effect on other aspects of the model, which is one reason why linear models are so commonly used.

Let's now regress `sex` on `alive_post` to see how sex affects candidates' post-election lifespans.

```{r, cache = TRUE}
fit_gov_2 <- stan_glm(data = ch9_gov,
                      formula = alive_post ~ sex - 1,
                      family = gaussian(),
                      refresh = 0)
```




```{r}
print(fit_gov_2, detail = FALSE)
```


In this regression, we use the -1 in the formula to make the output more straightforward, with no intercept to interpret. Now looking at the regression table output, let's interpret the Beta values for Female and Male, starting with a mathematical formula.

You may recall from algebra that the equation of a line is $$ y = a + b*x $$. It is defined by two coefficients *a* and *b*. The intercept coefficient *a* is the value of *y* when $$ x = 0 $$. The slope coefficient *b* for *x* is the increase in *y* for every increase of one in *x*.

However, when defining a regression line, we use slightly different notation: the equation of the regression line is $$ \hat{y} = {b_0} + {b_1} x  $$. The intercept coefficient is $$ {b_0} $$, so $$ {b_0} $$ is the value of $$ \hat{y} $$ when $$ x = 0 $$. The slope coefficient for *x* is $$ {b_1} $$, i.e., the increase in $$ \hat{y} $$ for every increase of one in *x*. Why do we put a "hat" on top of the *y*? It's a form of notation commonly used in regression to indicate that we have a "fitted value," or the value of *y* on the regression line for a given *x* value. This fitted value that falls on the regression line may differ from the observed value of *y* given that particular *x* value. The difference between the observed y-value and the predicted, or fitted, y-value is called the *residual*. 

<!-- HV: Are terms like fitted value and residual supposed to be in a certain font style to highlight them? -->

In many of the examples we will be discussing in this chapter, our regression equations will contain multiple beta values for all the different parameters we are interpreting. 

Now looking back to the regression model we just created, we see that there is no intercept. Instead of having a $$ {b_0} $$ value, we have $$ {b_m} $$ and $$ {b_f} $$ for male and female. This makes things easier to interpret. Without having to add or subtract anything from an intercept, this regression tells us that on average, women are expected to live 5840 days after running for governor, and men are expected to live 10395 days after running for governor.

This is a strange result, as men are expected to live twice as long as women. One explanation for this might be that women don't run for governor until later in life, and therefore are not expected to live as long.

<!-- HV: Should probably add more discussion of this result. -->

<!-- DK: Weird result, huh? Men live twice as long as women! Useful to discuss why that might be the case. -->

<!-- Perhaps of next is to understand what the intercept is. That is, this model is identical to the previous. -->

Now that we have interpreted the model using a -1 in the formula to get both a $$ {b_m} $$ value and a $$ {b_f} $$ value, let's take away the -1 and regress `sex` on `alive_post` to see how our equation changes.

```{r, cache = TRUE}
fit_gov_2a <- stan_glm(data = ch9_gov,
                      formula = alive_post ~ sex,
                      family = gaussian(),
                      refresh = 0)
```

```{r}
tbl_regression(fit_gov_2a, intercept = TRUE)
```

From this result, we can see that we no longer have a value for female, however we do have an intercept. In this regression our mathematical regression formula is $$ \hat{alivepost} = {b_0} + {b_m}* male  $$. $$ {b_0} $$ is our intercept value which here would be 5875. You may notice that this is very similar to the female value from before. In this type of model, our intercept represents the characteristic of the variable that is left unrepresented in the model. Here our slope, or $$ {b_m} $$ value is for when the candidate is male. Therefore, we can infer that the intercept value represents those who are not male: females.

When the candidate is a male, we add the beta for male to the intercept value, which gives us the average lifespan of a male gubernatorial candidate after an election. As we can see from adding $${b_m}$$ and $${b_0}$$, this value is the same as what we got for males in the previous model.

<!-- HV: Shouldn't the intercept be the same as the female value from the previous regression? Is the difference here due to running stan_glm? Kind of confused by this result. -->

```{r}
sex_means <- 
  governors %>% 
  group_by(sex) %>% 
  summarize(avg = mean(alive_post), .groups = "drop")

governors %>% 
  ggplot(aes(sex, alive_post)) + 
    geom_jitter(width = 0.1, alpha = 0.2) + 
    geom_point(data = sex_means, aes(y = avg), color = "red")
```

<!-- use posterior lin pred instead of sex_means to get fitted values -->

<!-- DK: All the above happens before this -->

```{r, cache = TRUE}
fit_gov_3 <- stan_glm(data = ch9_gov,
                      formula = alive_post ~ sex + alive_pre,
                      family = gaussian(),
                      refresh = 0)
```

```{r}
tbl_regression(fit_gov_3, intercept = TRUE)
```

<!-- DK: Cool, eh? It is (mostly?) an age effect! Controlling for age at the election, women live about as long as men, but they are much more likely be candidates as an older age. Again, what we are doing is slowly building more complex models, understanding what they mean. -->

<!-- Also, note that this is a "parallel slopes" model. Explain slowly what that means.  Create a plot. -->

<!-- Side note: I would have thought that overlapping CIs for male/female would equate to insignificance of sex dummy when the regression includes a intercept. But that does not seem to be the case. Am I missing something? -->

<!-- Make the graphic which shows two parallel lines, by calling two layers of geom_smooth().  -->

<!-- With this as warm-up, we are now in a position to explore interactions. -->

```{r, cache = TRUE}
fit_gov_4 <- stan_glm(data = ch9_gov,
                      formula = alive_post ~ sex*alive_pre,
                      family = gaussian(),
                      refresh = 0)
```

```{r}
tbl_regression(fit_gov_4, intercept = TRUE)
```

<!-- DK: Take your time explaining what this means! It is not trivial. Note that this is a non-parallel slopes model. -->


```{r, cache = TRUE}
fit_gov_5 <- stan_glm(data = ch9_gov,
                      formula = alive_post ~ state + sex*alive_pre,
                      family = gaussian(),
                      refresh = 0,
                      iter = 10000)
```



```{r}
tbl_regression(fit_gov_5, intercept = TRUE)
```

<!-- DK: Need to modify this to only show of the more interesting state coefficients. (Although we might show all the state pdfs in the graphic.) This a good place to discuss shrinkage, which is what is happening here. And that is probaly enough models. -->

## Temperance

```{r echo=FALSE, fig.margin=TRUE, fig.cap="Temperance"}
knitr::include_graphics("other/images/Temperance.jpg")
```

<!-- Use posterior_predict -->



## EDA of `shaming`

Imagine you are running for Governor and want to do a better job of getting your voters to vote. You recently read about a large-scale experiment showing the effect of sending out a voting reminder that "shames" citizens who do not vote. You are considering sending out a "shaming" voting reminder yourself. What will happen if you do? Will more voters show up to the polls? Additionally, on the day of the election a female citizen is randomly selected. What is the probability she will vote?    

Consider a new data set, `shaming`, corresponding to an experiment carried out by Gerber, Green, and Larimer (2008) titled "Social Pressure and Voter Turnout: Evidence from a Large-Scale Field Experiment". This experiment used several hundred thousand registered voters and a series of mailings to determine the effect of social pressure on voter turnout. 

Let's now do another EDA, starting off by running `glimpse()`.

```{r}
glimpse(shaming)
```

Here we see that `glimpse()` gives us a look at the raw data contained within the `shaming` data set. At the very top of the output, we can see the number of rows and columns, or observations and variables respectively. We see that there are 344,084 observations, with each row corresponding to a unique respondent. The "Columns: 10" tells us that there are 10 variables within this data set. Below this, we see a cutoff version of the entire data set that has the variables on the left as rows and the observations as a list separated by commas, as compared to the tibble output that presents with the variables as columns and the observations as rows running horizontally.

<!-- It may be worth mentioning that general_04 is always "yes", unlike all the other voting history variables which have values of "yes" and "no". Why is that? I *think* that this is caused by their sampling plan. They found all the people who voted in the 2004 general election. Then, the authors found their history. As we would expect, those people had sometimes voted in the past and sometime not. Then, the authors sent the mailing. The key dependent variable, primary_06, is coding 0/1, since that makes doing the statistics easier. -->

From this summary, we get an idea about some of the variables we will be dealing with. Some variables that will be of interest to us are `sex`, `hh_size`, and `primary_06`. The variable `hh_size` tells us the size of the respondent's household, and `primary_06` tells us whether or not the respondent voted in the 2006 Primary election. 

There are a few things to note while exploring this data set. You may -- or may not -- have noticed that the only response to the `general_04` variable is "Yes". In their published article, the authors note that "Only registered voters who voted in November 2004 were selected for our sample" (Gerber, Green, Larimer, 2008). After this, the authors found their history then sent out the mailings.

It is also important to identify the dependent variable and its meaning. In this shaming experiment, the dependent variable is `primary_06`, which is a variable coded either 0 or 1 for whether or not the respondent voted in the 2006 primary election. This is the dependent variable because the authors are trying to measure the effect that the treatments have on the proportion of people who vote in the 2006 general election.

<!-- HV: Should I include discussion of the left-hand variable (treatment?) here? Or wait until we move into the regressions? -->

The voting results from other years, such as 2002 and 2004, are of less interest to us and can be removed from the abbreviated data set. In addition to removing `general_04`, `primary_02`, `general_02`, or `primary_04`, we also will not be taking particular interest in `birth_year`, or `no_of_names` within this chapter.
<!-- HV: should I explain why we are not using any of these variables? why they are not of great use to us? -->

By narrowing down the set of variables we are looking at and investigating, we will find more meaningful relationships among them. However, we have not yet discussed the most important variable of them all: `treatment`. The `treatment` variable is a factor variable with 5 levels, including the control. Since we are curious as to how sending mailings affects voter turnout, the treatment variable will tell us about the impact each type of mailing can make. Let's start off by taking a broad look at the different treatments.
<!-- HV: Is it okay to say the first sentence of this paragraph? -->

```{r}
shaming %>%
  count(treatment)
```

Four types of treatments were used in the experiment, with voters receiving one type of mailing. All of the mailing treatments carried the message, "DO YOUR CIVIC DUTY - VOTE!". 

The first treatment, Civic Duty, also read, “Remember your rights and responsibilities as a citizen. Remember to vote." This message acted as a baseline for the other treatments, since it carried a message very similar to the one displayed on all the mailings.

In the second treatment, Hawthorne, households received a mailing which told the voters that they were being studied and their voting behavior would be examined through public records. This adds a small amount of social pressure to the households receiving this mailing.

In the third treatment, Self, the mailing includes the recent voting record of each member of the household, placing the word "Voted" next to their name if they did in fact vote in the 2004 election or a blank space next to the name if they did not. In this mailing, the households were also told, “we intend to mail an updated chart" with the voting record of the household members after the 2006 primary. By emphasizing the public nature of voting records, this type of mailing exerts more social pressure on voting than the Hawthorne treatment.

The fourth treatment, Neighbors, provides the household members' voting records, as well as the voting records of those who live nearby. This mailing also told recipients, "we intend to mail an updated chart" of who voted in the 2006 election.

For now, let's focus on a subset of the data.

```{r}
ch9 <- shaming %>% 
  mutate(solo = ifelse(hh_size == 1, TRUE, FALSE)) %>% 
  mutate(age = 2006 - birth_year) %>% 
  select(primary_06, treatment, solo, sex, age)
```

We create the variable `solo`, which is TRUE for voters who live alone and FALSE for those that do not. We are curious to see if the treatment effect, if any, is the same for voters who live alone as it is for those who do not.

```{r}
ch9 %>% 
  skim()
```


<!-- DK: Add discussion of what you see here. No need to drop missing values since there aren't any. I think this next discussion can be dropped. -->


While some summarizing commands such as `glimpse()` gives us a good look at the possible values for the variables, it is difficult to read it in terms of individual observations. Recall that the *observational unit* is what is being measured. With the `shaming` data set, the observational unit would be the voter respondent. To get a better sense of some respondents' information, let's use `sample_n()` to gather a random sample of *n* observations from the data set.
<!-- HV: Does this belong here? -->

```{r}
ch9 %>% 
  sample_n(10)
```

Now we have a table with 5 random observations and the respondents' information in a regular table output. By taking a few random samples, we may start to see some patterns within the data. 

Now we have a table with 5 random observations and the respondents' information in a regular table output. By taking a few random samples, we may start to see some patterns within the data. Do you notice anything in particular about the variable `treatment`?

One other helpful summarizing technique we can use is `skim()`. To make the information it contains simpler, we will only be looking at three variables: `primary_06`, `treatment`, and `sex`. 

```{r}
shaming %>% 
  select(primary_06, treatment, sex) %>% 
  skim()
```

By running the `skim()` command, we get a summary of the data set as a whole, as well as the types of variables and individual variable summaries. At the top we see the number of columns and rows within the selected data set. Below this we are given a list with the different types of variables, or columns, and how often they appear within the data we are skimming. Following this, the variables are then separated by their column type, and we are given individual summaries based on the type. 

<!-- 2) `primary_06` as a function of `treatment` and `solo` and of their interaction. We will build up this model step-by-step, very similar to how we explored the effect of treatment in chapter 8. But we go deeper because  we are learning about interactions. Key thing is to go through all the themes.Rmd issues, at least until prediction. Note that this situation is different from Chapter 8 in that fitted values and predicted values are not the same thing! The fitted value, for a combination of values for treatment and solo, is something 0.30, meaning that 30% of the people in this bucket votes. But the predicted value must be 0 or 1. Either you voted or you didn't. This example is clearly causal and so you need a Rubin Table with 4 potential outcome columns. The key difference in this chapter is that we are using lots of right hand side variables, both continuous and discrete. -->

<!-- 3) EDA of `nes`. This can be fairly quick. Again, we won't use all the variables. Only discuss the ones we do use. One of the variables should be year. We want to show off Gelman's trick by plotting things by year. -->

<!-- 4) We are making a predictive model of what as a function of what other stuff? Want to use a continuous variable and some discrete variables as well. Interactions to.  -->

<!-- 5) I don't think we bother with a scenario which requires a bootstrap. Or should we?  -->

<!-- 6) Prediction. How do we use our model to make predictions? Bring the discussion back to the way that we opened the chapter with a problem. -->



Having created models with one parameter in Chapter \@ref(#one-parameter) and two parameters in Chapter \@ref(#two-parameters), you are now ready to make the jump to $N$ parameters.  The more parameters we include in our models, the more flexible they can become. But we must be careful of *overfitting*, of making models which are inaccurate because they don't use enough data to accurately estimate those parameters. The tension between overfitting and underfitting is central to the practice of data science.
<!-- HV: Where does this belong? -->

### Wisdom

```{r echo=FALSE, fig.margin=TRUE, fig.cap="Wisdom"}
knitr::include_graphics("other/images/Wisdom.jpg")
```


### Justice

```{r echo=FALSE, fig.margin=TRUE, fig.cap="Justice"}
knitr::include_graphics("other/images/Justice.jpg")
```


### Courage

```{r echo=FALSE, fig.margin=TRUE, fig.cap="Courage"}
knitr::include_graphics("other/images/Courage.jpg")
```


### Temperance

```{r echo=FALSE, fig.margin=TRUE, fig.cap="Temperance"}
knitr::include_graphics("other/images/Temperance.jpg")
```


## Causal Effects of `treament`

We will now be looking into the causal effect of the treatment variable on the 2006 primary election. To start, let's build a model using `stan_glm()` followed by a regression table. 

```{r, cache=TRUE}
# obj.1 <- stan_glm(data = shaming, 
#                 formula = primary_06 ~ treatment - 1, 
#                 family = gaussian(), 
#                 refresh = 0)
```

```{r, echo=FALSE}
# tbl_regression(obj.1)
```

This table shows us each of the five treatments and their beta coefficients, along with a 95% Confidence Interval for these coefficients. The Control provides us with a baseline.

<!-- HV: Not exactly sure how to interpret this using causal effect... Should I be making preceptor tables here? -->



<!-- Talk about what these results mean.  Then, create the same model but with a different structure. -->


```{r, cache=TRUE}
# obj.2 <- stan_glm(data = shaming, 
#                 formula = primary_06 ~ treatment, 
#                 family = gaussian(), 
#                 refresh = 0)
```


```{r, echo=FALSE}
# tbl_regression(obj.2)
```

<!-- Explain how these two models are the same, except in how they define the parameters. Show us the math like Gelman does. Write down the math. For simple. -->



<!-- Once we talk about these things --- and, again, this is exactly what we have talked about in chapter 8 --- we can do a bit more. Like discuss how we are using 99%, because there is nothing magical aboyt 95%, other than convention. I also think it would be fun to show a nice graphic of this, highlighting how the estimates for Civic and Hawthorne overlap.  -->


### Interactions

<!-- This is new. With only two parameters, we can't really look at interaction effects. Need to discuss interaction effects in general. Also, note that heterogenous treatment effects are the same thing as interaction effects that involve a treatment effect as one of the variables.  -->

<!-- Feel free to build up this code, and other examples, more slowly than I am doing it here. -->

```{r, cache=TRUE}
# obj.3 <- stan_glm(data = shaming, 
#                 formula = primary_06 ~ sex + treatment + sex:treatment, 
#                 family = gaussian(), 
#                 refresh = 0)
```

```{r, echo=FALSE}
# tbl_regression(obj.3)
```

<!-- Takes a while to explain what all this means. -->

<!-- Two key issues: 1) Interpreting lots of parameters in a model. interactions, heterogenous treatment effects. shaming using lm().  -->

<!-- Treatment effect is not the same thing as a coefficient. -->

<!-- 
intercept

Interactions --- use: income ~ party*something

heterogeneous treatment effects --- use:  att_start ~ treatment*something 
just a fancy way of saying interaction effects, but with a variable which us causal


What problems do we face? All the things that make modeling difficult. Why is this so hard? -->

<!-- Centering. -->

<!-- Might naively just take the value for each bucket. But that overfits! Need to put down some structure, like ordering. -->

<!-- income category, party id, pooling, age, -->

<!-- overfitting/underfitting bias/variance -->

<!-- We must have left bootstrapping behind by now. No more bootstraps, at least for the purpose of calculating uncertainty. (We will use it later for the purpose of out-of-sample testing and avoiding overfitting.) Key lesson is that overfitting is easy. You can't just estimate a value for each cell. You need to smooth and borrow strength. Of course, the only way to do that is with a Bayesian approach. Right? We don't want to get into hacked likelihood approaches. -->

<!-- cces looks perfect for this project. There are 400,000 rows, so it seems like you ought to have plenty of data for anything you want, but once you realize there are 51 states and 10 years, things get sparse fast. We only have 15 observations, for example, for Wyoming in 2007. Once you start subsetting by race and education, you have no choice but to start borrowing strength.  -->

<!-- So, just what will we use? rstanarm(). If so (and if we have not introduced it earlier), we can begin with seeing how it is similar to lm() and then expand. This means that, in one paramter chapter, we should be doing lm( ~ 1). In two parameter, lm( ~ treatment) --- if treatment is zero one --- or, perhaps better, lm( ~ -1 + treatment) if treatment is a factor/character with two levels. We might also have introduced  -->
