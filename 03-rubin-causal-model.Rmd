---
output_yaml:
  - _output.yml
---

# Rubin Causal Model {#rubin-causal-model}

```{r, include=FALSE}
library(tidyverse)
```

<!-- # Next summer? -->

<!-- Make the math in the examples here and in the tutorial easy enough to do in our heads. In particular, the average value for any column should be easy to calculate. -->

<!-- 0) Add Sliding Doors: -->

<!-- ```{r, echo=FALSE} -->
<!-- knitr::include_app("https://www.youtube.com/watch?v=BvUbv4iwbDs") -->
<!-- ``` -->

<!-- 1) Deal with references. Can't have a References section. Figure out the right bibtex entry for reference you (!) want to keep. Place them in bib/references.bib. Call them with @entry somewhere in your chapter. -->

 <!-- Fix the tutorial. Delete the Try Agains. Give enough blank lines for what you expect them to write. -->

<!-- Consider adding permutation tests -->

<!-- Does RCM connect to concepts like regression to the mean and the garden of forking paths? If so, we should add sections to those appendices. -->

<!-- Lots of useful material here: https://chabefer.github.io/STCI/ -->

<!-- unit/item nonresponse -->
<!-- treat potential outcomes as fixed (can we do this with regression?) -->

Have you ever wondered what the world would be like without you?

```{r, echo=FALSE}
knitr::include_app("https://www.youtube.com/embed/cR7p-IB6INM")
```


So did George Bailey in the movie "It's a Wonderful Life". The movie follows George as he explores a world in which he was never born. It is clear that he had a profound impact on the lives of many people in his community.

By showing what the world would have been like without George, we get an idea of the causal effect of his life on his town and the people who live there. We will be looking at causal effects throughout the rest of this chapter using the Rubin Causal Model. 

```{r echo=FALSE, fig.cap="[Don Rubin was a professor of Statistics at  Harvard.](https://www.uni-bamberg.de/fileadmin/bagss/Bilder/Editorial/21711197.jpg).", fig.margin = TRUE}
knitr::include_graphics("03-rubin-causal-model/images/don_rubin.jpg")
```

The Rubin Causal Model (RCM) is an approach to the statistical analysis of cause and effect based on the framework of potential outcomes, created by Donald Rubin. 


## Preceptor Tables

A **Preceptor Table** is a table with rows and columns for all the data that we would (reasonably) like to have, such that, if all the cells have data, the thing we want to know is trivial to calculate. Preceptor Tables can vary depending on the number of rows and columns they have, as well as the amount of data that is missing from them. We use question marks as placeholders for the data we are missing in a Preceptor Table.

Assume that there are five adult brothers and you are given four of their heights. What is the average height of all five brothers? Because we are not given it, we can use statistics to make a best guess. Let's look at a Preceptor Table for our problem:

```{r echo = FALSE}
tibble(ID = c("Robert", "Andy", "Beau", "Ishan", "Nicolas"),
       Heights = c("178", "?", "172", "173", "165")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(ID = md("ID"),
                Heights = "Heights (cm)") %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(ID))) %>%
  tab_style(cell_text(align = "left", v_align = "middle"),
            locations = cells_column_labels(columns = vars(ID))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(ID)) %>%
  tab_spanner(label = "Outcome", columns = vars(Heights))
```

In this case, we have a row for each brother and a column for their height. We will always have an ID column in Preceptor Tables so that we can identify different units. `r margin_note("The ID column is always furthest to the left.")` In addition to the ID column, we call the column with the brother's heights an outcome column. `r margin_note("Outcomes columns are always right after the ID column.")` There are other types of columns that might be included in a Preceptor Table that we will introduce soon!

We are interested in predicting Andy's height. One guess is just an average of the other four brothers: $$\frac{(178 + 165 + 172 + 173)}{4} = 172 cm$$ How realistic do we think that best guess is? We should consider things like why we know the four other brothers' heights. Were they sampled randomly? Or do we know their heights because they are the tallest in the family? In that case would it make sense to use an average for our best guess of Andy's height? Probably not! 

Now let's think about a slightly more complex problem. Say we have the heights of 100 Harvard students, and from that we want to know the average height of students in the school. Let's make another Preceptor Table: 

`r margin_note("We can't show all 6,700 rows, so the elipses represents all the rows we are ignoring. You can imagine some of the hidden rows have heights recorded, but most are question marks.")`

<!-- DK: The elipses should be vertical, not horizontal in all these tables. -->

```{r echo = FALSE}
tibble(ID = c("Student 1", "Student 2", "...", "Student 473", "Student 474",
              "...", "Student 3,258", "Student 3,259", "...", "Student 6,700"),
       Heights = c("?", "?", "...", "172", "?", "...", "?", "162", "...", "?")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(ID = md("ID"),
                Heights = "Heights (cm)") %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(ID))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle"), 
            locations = cells_column_labels(columns = vars(ID))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(ID)) %>%
  tab_spanner(label = "Outcome", columns = vars(Heights))
```

Again, are these 100 students randomly sampled? Could we estimate the 90th percentile of height in the student population? These questions are more complicated, and we might be less confident in our best guess. Now let's say we are given some characteristics other than height for the 100 sampled students, i.e., sex and age. 

```{r echo = FALSE}

tibble(ID = c("Student 1", "Student 2", "...", "Student 473", "Student 474", 
              "...", "Student 3,258", "Student 3,259", "...", "Student 6,700"),
       Age = c("?", "?", "...", "19", "?", "...", "?", "20", "...", "?"), 
       Sex = c("?", "?", "...", "M", "?", "...", "?", "F", "...", "?"),
       Heights = c("?", "?", "...", "172", "?", "...", "?", "162", "...", "?")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(ID = md("ID"),
                Heights = "Heights (cm)") %>%
  cols_move(columns = vars(Heights), after = vars(ID)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(ID))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle"), 
            locations = cells_column_labels(columns = vars(ID))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(ID)) %>%
  tab_spanner(label = "Outcome", columns = vars(Heights)) %>%
  tab_spanner(label = "Covariates", columns = vars(Age, Sex))
```

You'll notice our Preceptor Table has a new type of column: **covariates**. Are we better able to forecast a random students height if we are given their age and sex? 

Throughout the rest of the book you will learn to solve similar problems while also considering the intricacies that plague even the simplest questions.

So far, we have only asked predictive questions. This chapter, however, primarily focuses on causal inference. 

## Causal effect

```{r echo=FALSE, fig.cap="This study was conducted by Ryan Enos.", fig.margin = TRUE}
knitr::include_graphics("03-rubin-causal-model/images/enos_seal.png")
```

The Rubin Causal Model (RCM) is based on the idea of **potential outcomes.** Consider an experiment which studied attitudes toward immigration among Boston commuters. Individuals were exposed to one of two possible conditions, and then their attitudes towards immigrants were measured. One condition was being on a train platform near individuals speaking Spanish. The other was being on a train platform without Spanish-speakers. To calculate the causal effect of having Spanish-speakers nearby, we need to compare the outcome for an individual in one possible state of the world (with Spanish-speakers) to another (without Spanish-speakers).`r margin_note("If you are confused on why it is impossible to observe both potential outcomes, reference section 'Other solutions to the Fundamental Problem of Causal Inference'.")` It is impossible to observe both potential outcomes at once. One of the potential outcomes is always missing. `r margin_note("Formally defined: The Fundamental Problem of Causal Inference is that directly observing unit-level causal effects is impossible.")` This dilemma is the *Fundamental Problem of Causal Inference*.

In most circumstances, we are interested in comparing two experimental manipulations, one generally termed "treatment" and the other "control." `r margin_note("The labels 'treatment' and 'control' are somewhat arbitrary.")` The difference between the potential outcome under treatment and the potential outcome under control is called a "causal effect" or a "treatment effect."  The scenario that didn't actually happen, and thus that we didn't observe, is called a "counterfactual." 

Thus, according to the RCM, the **causal effect** of being on the platform with Spanish-speakers is the *difference* between what your attitude would have been under "treatment" (with Spanish-speakers) and "control" (no Spanish-speakers).

`r margin_note("The survey consisted of 3 questions, with 1 being the most liberal answer and 5 being the most conservative. The range of attitudes therefore goes from 3 to 15.")`

Low numbers indicate liberal attitudes towards immigrants and high numbers indicate more conservative attitudes. If your attitude towards immigrants would have been a 13 with Spanish-speakers and a 9 without Spanish-speakers, then the causal effect of being on a platform with Spanish-speakers is a 4-point increase in your attitude score.

We will use the variable $Y$ to represent values we are interested in understanding (potential outcomes). $Y$ is called the *response variable* because it is the variable we want to explain in the context of an experiment. In our case this would be the attitude score.

If we are trying to understand a causal effect, we need two variables: so that control and treated values can be represented separately.`r margin_note("The response variables will therefore vary based on treatment status.")` We will use the variables $Y_t$ and $Y_c$. 

### Potential outcomes

Suppose that Yao is one of the commuters surveyed in this experiment. If we were omniscient, we would know the outcomes for Yao under both treatment (with Spanish-speakers) and control (no Spanish-speakers). We can show this using an ideal Preceptor Table. This Preceptor Table is considered *ideal* because we are not missing any data, and so calculating the number we are interested in is trivial.

`r margin_note("We are using the phrase 'Attitude if' in this ideal Preceptor Table because of the Fundamental Problem of Causal Inference. We cannot know both of Yao's potential outcomes. Instead by *pretending* we are omniscient, we can fill in the values that normally would be impossible to observe. In that case, we have both of Yao's potential outcomes without him being assigned to either the Control or Treatment group. We *just know* his attitude in both situations, and are using this to clarify what an ideal Preceptor Table would look like, even if this is impossible to know.")`

```{r, echo = FALSE, fig.align = 'left'}
# First, we create a tibble with the values we want for the table

tibble(ID = "Yao",
       ytreat = "13",
       ycontrol = "9") %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(ID = md("ID"),
                ytreat = "Attitude if Treated",
                ycontrol = "Attitude if Control") %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(ID)))  %>%
  tab_style(style = cell_text(align = "left", v_align = "middle"), 
            locations = cells_column_labels(columns = vars(ID))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(ID)) %>%
  tab_spanner(label = "Outcomes", columns = vars(ytreat, ycontrol))
```

From this table we only know the causal effect on Yao. Everyone else in the study might have their attitude score go down if treated (more liberal). Regardless of what the causal effect is on other subjects, the causal effect for Yao of being on the train platform with Spanish-speakers is a shift towards a more conservative attitude.

In a Preceptor Table we can also use response variables to describe potential outcomes.

`r margin_note("$Y_{t}$ is the same as 'Attitude if Treated'. Recall this response variable represents potential outcomes which result from being treated ($t$)")`
`r margin_note("$Y_{c}$ is the same as 'Attitude if Control'. Recall this response variable represents potential outcomes which result from being a control ($c$)")`

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = "Yao",
       ytreat = "13",
       ycontrol = "9") %>%
  
  # Then, we use the gt function to make it pretty
  
gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t$$"),
                ycontrol = md("$$Y_c$$")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  fmt_markdown(columns = TRUE) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol))
```

### Estimands

In order to understand estimands, let's look again at our ideal Preceptor Table for Yao:

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = "Yao",
       ytreat = "13",
       ycontrol = "9") %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t$$"),
                ycontrol = md("$$Y_c$$")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  fmt_markdown(columns = TRUE) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol))
```

One possible variable we might be interested is causal effect. `r margin_note("Remember this is the difference between Yao's potential outcomes under treatment and control.")` For convenience, let's add this to our ideal Preceptor Table:

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = "Yao",
       ytreat = "13",
       ycontrol = "9",
       ydiff = "+4") %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t$$"),
                ycontrol = md("$$Y_c$$"),
                ydiff = md("$$Y_t - Y_c$$")) %>%
  cols_move(columns = vars(ytreat, ycontrol), after = vars(subject)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  fmt_markdown(columns = TRUE) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol)) %>%
  tab_spanner(label = "$$\\text{Estimand}$$", vars(ydiff))
```

But remember that in a actual Preceptor Table we will have a bunch of missing data! We normally can't use simple arithmetic to calculate the causal effect on Yao's attitude toward immigration. Instead we will be required to estimate. An **estimand** is some variable in the real world that we are trying to measure. `r margin_note("The estimand in this case is $Y_{t}-Y_{c}$, not $+4$.")` An estimand is not the *value* you calculated, but is rather the *unknown variable* you want to estimate. 

We will continue to use ideal Preceptor Tables to give you an idea of some examples of estimands, but remember normally estimands cannot be found using arithmetic because there are lots missing values in actual Preceptor Tables!

Treatment effect is only one possible estimand we might be interested in. The ratio of potential outcomes is another estimand:

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = "Yao",
       ytreat = "13",
       ycontrol = "9",
       ydiff = "+4",
       yratio = "13/9") %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t$$"),
                ycontrol = md("$$Y_c$$"),
                ydiff = md("$$Y_t - Y_c$$"),
                yratio = md("$$Y_t / Y_c$$")) %>%
  cols_move(columns = vars(ytreat, ycontrol), after = vars(subject)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  fmt_markdown(columns = TRUE) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol))  %>%
  tab_spanner(label = "$$\\text{Estimands}$$", vars(yratio, ydiff)) 
```


The percentage change between outcome under treatment and outcome under control is another estimand.

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = "Yao",
       ytreat = "13",
       ycontrol = "9",
       yperc = "+44.4%") %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t$$"),
                ycontrol = md("$$Y_c$$"),
                yperc = md("$$(Y_t - Y_c) / Y_c \\times 100$$")) %>%
  cols_move(columns = vars(ytreat, ycontrol), after = vars(subject)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  fmt_markdown(columns = TRUE) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol)) %>%
  tab_spanner(label = "$$\\text{Estimand}$$", vars(yperc))
```

### Multiple units

Generally a study has individuals who each have their own unique potential outcomes. In that case, it no longer makes sense to just have $Y_t$ and $Y_c$ represent all of the individual potential outcomes. More notation is needed to allow us to differentiate between individuals. 

In other words, there needs to be a distinction between $Y_t$ for Yao, and $Y_t$ for Emma. We could do something like $Y_t(Yao)$ and $Y_t(Emma)$, but that would be an ineffective approach if we wanted to fill out a full Preceptor Table. Instead, we use the variable $u$ ($u$ for "unit") to indicate that the outcome under control and the outcome under treatment might be different for each individual unit (person). The $u$ represents all the different individuals. 

Now, instead of $Y_t$, we will use $Y_t(u)$ to represent 'Attitude if Treated'. If you want to talk about only Emma, you could say "Emma's Attitude if Treated" or "$Y_t(u = Emma)$" or "the $Y_t(u)$ for Emma", but not just $Y_t$. That notation is too ambiguous when there is more than one subject.

Let's look at an ideal Preceptor Table with more subjects using our new notation: 

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Yao", "Emma", "Cassidy", "Tahmid", "Diego"),
       ytreat = c("13", "11", "11", "9", "5"),
       ycontrol = c("9", "11", "10", "12", "4"),
       ydiff = c("+4", "0", "+1", "-3", "+1")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  cols_move(columns = vars(ytreat, ycontrol), after = vars(subject)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  fmt_markdown(columns = TRUE) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol))  %>%
  tab_spanner(label = "$$\\text{Estimand}$$", vars(ydiff))
```

From this ideal Preceptor Table, there are many possible estimands we might be interested in. Consider some examples, along with their true values:

::: {.fullwidth} 

- A potential outcome for one person, e.g., Yao's potential outcome under treatment ($13$).  
- A causal effect for one person, such as for Emma.  This is the difference between the potential outcomes, which we have provided as its own column ($11 - 11 = 0$).
- The most positive causal effect.  Here, that is $+4$, for Yao ($13 - 9 = +4$).
- The most negative causal effect.  Here, that is $-3$, for Tahmid ($9 - 12 = -3$).
- The median causal effect ($+1$).
- The median percentage change.  To do this, calculate the percentage change for each person.  You'll get 5 percentages: $+44.4\%$, $0.0\%$, $+10.0\%$, $-25.0\%$, and $+25.0\%$.  The median is $+10.0\%$.
- The total number of people for whom the causal effect is positive: $3$.
- And so on. There are a lot of things one might care about!

:::



All of the variables we calculated above are examples of estimands we might be interested in. One very common estimand we might care about has its own name, the **average treatment effect**. The average treatment effect (often abbreviated **ATE**) is the mean of all the causal effects. Here, the mean is $+0.6$.

Remember what an actual Preceptor Table riddled with question marks looks like:

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Yao", "Emma", "Cassidy", "Tahmid", "Diego"),
       ytreat = c("13", "11", "?", "?", "5"),
       ycontrol = c("?", "?", "10", "12", "?"),
       ydiff = c("?", "?", "?", "?", "?")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  cols_move(columns = vars(ytreat, ycontrol), after = vars(subject)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  fmt_markdown(columns = TRUE)  %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol))  %>%
  tab_spanner(label = "$$\\text{Estimand}$$", vars(ydiff))
```

`r margin_note("'We should start the inferential process with clear statements of scientific objectives and associated estimands, and a precise description of the hypothetical data set from which we would simply calculate the estimands. Such a data set could be composed mostly of unobserved or even unobservable values, but it defines the objects of inference.' ^[Rubin 2011]")`

Calculating values from this table is no longer a simple math problem. Don't worry! We will look at ways to solve for estimands we are interested in from an actual Preceptor Table soon. 

### Preceptor Table structure

<!-- DK: Clean this up. Can an outcome be an estimand? Probably. But then estimands and outcomes can be separate categories of columns below. -->

Remember a Preceptor Table has all of the rows and columns of data that we would reasonably like to know. The first column in a Preceptor Table is always the ID column. We can then have columns under the subheadings 'Outcomes', 'Estimands', and 'Covariates' in that order. The final structure of a Preceptor Table should look like this, and include only whatever columns and rows are necessary for the problem you are trying to solve:

```{r, echo = FALSE}

tibble(subject = c("1", "2", "3", "4", "5"),
       age = c("?", "?", "?", "?", "?"), 
       sex = c("?", "?", "?", "?", "?"),
       ytreat = c("?", "?", "?", "?", "?"),
       ycontrol = c("?", "?", "?", "?", "?"),
       ydiff = c("?", "?", "?", "?", "?"),
       yperc = c("?", "?", "?", "?", "?")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
             age = md("$$\\text{Age}$$"),
             sex = md("$$\\text{Sex}$$"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$"),
             yperc = md("$$((Y_t - Y_c) / Y_c) \\times 100$$")) %>%
  cols_move(columns = vars(ytreat, ycontrol), after = vars(subject)) %>%
  cols_move(columns = vars(age, sex), after = vars(yperc)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  fmt_markdown(columns = TRUE) %>%
  tab_spanner(label = "$$\\text{Covariates}$$", vars(age, sex)) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol)) %>%
  tab_spanner(label = "$$\\text{Estimands}$$", vars(ydiff, yperc))
```

An ideal Preceptor Table has no missing data, whereas an actual Preceptor Table has question marks representing missing data. See this lecture from Gov 51 for a thorough discussion.

```{r, echo=FALSE, fig.margin = TRUE}
knitr::include_app("https://www.youtube.com/embed/gyRZSzCtU_o")
```

## Simple models

How can we fill in the question marks?  Because of the fundamental problem of causal inference, we can never *know* the missing values. Because we can never know the missing values, we must make assumptions. "Assumption" just means that we need a "model," and all models have parameters.

### A single value for tau

`r margin_note("A parameter is some variable we can calculate using our data. A parameter can be an estimand by itself, like the average of the control group. An estimand can also require a more complex calculation involving multiple parameters.")`

One model might be that the causal effect is the same for everyone. There is a single parameter, $\tau$, which we then estimate. ($\tau$ is a Greek letter --- spelled phonetically as "tau" --- which rhymes with "cow.") Once we have an estimate, we can fill in the Preceptor Table because, knowing it, we can estimate what the unobserved potential outcome is for each person. We use our assumption about $\tau$ to estimate the counterfactual outcome for each unit. Now our estimand is $\tau$; whether this is a sensible estimand depends on how close the real world conforms to our assumption that the causal effect is the same for everyone.

Remember what our Preceptor Table looks like with all of the missing data: 

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Yao", "Emma", "Cassidy", "Tahmid", "Diego"),
       ytreat = c("13", "11", "?", "?", "5"),
       ycontrol = c("?", "?", "10", "12", "?"),
       ydiff = c("?", "?", "?", "?", "?")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  cols_move(columns = vars(ytreat, ycontrol), after = vars(subject)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol)) %>%
  tab_spanner(label = "$$\\text{Estimand}$$", vars(ydiff)) %>%
  fmt_markdown(columns = TRUE)
```

If we assume $\tau$ is the treatment effect for everyone, how do we fill in the table? We are using $\tau$ as an estimate for causal effect. It therefore has to be true that $Y_t(u) - Y_c(u) = \tau$. Using simple algebra, it is then clear that $Y_t(u) = Y_c(u) + \tau$ and $Y_c(u) = Y_t(u) - \tau$. In other words, you could add it to the observed value of every observation in the control group (or subtract it from the observed value of every observation in the treatment group), and thus fill in all the missing values.

Assuming there is a constant treatment effect, $\tau$, for everyone, filling in the missing values would look like this: 

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Yao", "Emma", "Cassidy", "Tahmid", "Diego"),
       ytreat = c("13", "11", "$$10 + \\tau$$", "$$12 + \\tau$$", "5"),
       ycontrol = c("$$13 - \\tau$$", "$$11 - \\tau$$", "10", "12", "$$5 - \\tau$$"),
       ydiff = c("$$\\tau$$", "$$\\tau$$", "$$\\tau$$", "$$\\tau$$", "$$\\tau$$")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  cols_move(columns = vars(ytreat, ycontrol), after = vars(subject)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol)) %>%
  tab_spanner(label = "$$\\text{Estimand}$$", vars(ydiff)) %>%
  fmt_markdown(columns = TRUE)
```

Now we need to find an estimate for $\tau$ in order to fill in our table with numbers that we can begin to understand. Again, we are assuming $Y_t(u) - Y_c(u) = \tau$. 

That equation outlines a clear way in which we can estimate $\tau$. We can subtract the average of the observed control values from the observed treated values. $$((13 + 11 + 5) / 3) - ((10 + 12) /  2)$$ $$9.67 - 11 = -1.33$$

This gives us an estimate of $-1.33$ for $\tau$. Let's fill in our missing values by adding $\tau$ to the observed values under control and by subtracting $\tau$ from the observed value under treatment like so:

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Yao", "Emma", "Cassidy", "Tahmid", "Diego"),
       ytreat = c("13", "11", "$$10 + (-1.33)$$", "$$12 + (-1.33)$$", "5"),
       ycontrol = c("$$13 - (-1.33)$$", "$$11 - (-1.33)$$", "10", "12", "$$5 - (-1.33)$$"),
       ydiff = c("-1.33", "-1.33", "-1.33", "-1.33", "-1.33")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  cols_move(columns = vars(ytreat, ycontrol), after = vars(subject)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol)) %>%
  tab_spanner(label = "$$\\text{Estimand}$$", vars(ydiff)) %>%
  fmt_markdown(columns = TRUE)
```

Which gives us:

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Yao", "Emma", "Cassidy", "Tahmid", "Diego"),
       ytreat = c("13", "11", "8.67", "10.67", "5"),
       ycontrol = c("14.33", "12.33", "10", "12", "6.33"),
       ydiff = c("-1.33", "-1.33", "-1.33", "-1.33", "-1.33")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  cols_move(columns = vars(ytreat, ycontrol), after = vars(subject)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol)) %>%
  tab_spanner(label = "$$\\text{Estimand}$$", vars(ydiff)) %>%
  fmt_markdown(columns = TRUE)
```

### Two values for tau

A second model might assume that the causal effect is constant within some other categories, and not across the entire sample. Maybe one of those categories is sex? Perhaps it is $\tau_F$ for females and $\tau_M$ for males. We are making this assumption to give us a different model with which to fill in the missing values in our table. The key concept is that we can't make any progress unless we make some assumptions. That is an inescapable result of the Fundamental Problem of Causal Inference.

Let's look at this particular model in which we think sex has an impact on treatment effect:

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Yao", "Emma", "Cassidy", "Tahmid", "Diego"),
       ytreat = c("13", "11", "$$10 + \\tau_F$$", "$$12 + \\tau_M$$", "5"),
       ycontrol = c("$$13 - \\tau_M$$", "$$11 - \\tau_F$$", "10", "12", "$$5 - \\tau_M$$"),
       ydiff = c("$$\\tau_M$$", "$$\\tau_F$$", "$$\\tau_F$$", "$$\\tau_M$$", "$$\\tau_M$$")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  cols_move(columns = vars(ytreat, ycontrol), after = vars(subject)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol)) %>%
  tab_spanner(label = "$$\\text{Estimand}$$", vars(ydiff)) %>%
  fmt_markdown(columns = TRUE)
```

We would have two different estimates for $\tau$.

$\tau_M$ would be $$(13+5)/2 - 12 = -3$$
$\tau_F$ would be $$(11-10 = +1)$$ 
Using those values, we would fill out our new table like this: 

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Yao", "Emma", "Cassidy", "Tahmid", "Diego"),
       ytreat = c("13", "11", "$$10 + (+1)$$", "$$12 + (-3)$$", "5"),
       ycontrol = c("$$13 - (-3)$$", "$$11 - (+1)$$", "10", "12", "$$5 - (-3)$$"),
       ydiff = c("-3", "+1", "+1", "-3", "-3")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  cols_move(columns = vars(ytreat, ycontrol), after = vars(subject)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol)) %>%
  tab_spanner(label = "$$\\text{Estimand}$$", vars(ydiff)) %>%
  fmt_markdown(columns = TRUE)
```

Which gives us:

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Yao", "Emma", "Cassidy", "Tahmid", "Diego"),
       ytreat = c("13", "11", "11", "9", "5"),
       ycontrol = c("16", "10", "10", "12", "8"),
       ydiff = c("-3", "+1", "+1", "-3", "-3")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  cols_move(columns = vars(ytreat, ycontrol), after = vars(subject)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol)) %>%
  tab_spanner(label = "$$\\text{Estimand}$$", vars(ydiff)) %>%
  fmt_markdown(columns = TRUE)
```

We now have two different estimates for Emma (and for everyone else in the table). When we estimate $Y_c(Emma)$ using an assumption of constant treatment effect (a single value for tau), we get 12.33. When we estimate assuming treatment effect is constant for each sex, we calculate that $Y_c(Emma) = 10$. This difference between our estimates for Emma is the heart of inference. 
 
<!-- EC: One more sentence here about how randomized assignments could be extrapolated to reflect the population would be great -->

### Heterogenous treatment effects

<!-- $\widehat{ATE}$ can be a useful estimand in telling us about treatment effect. This sort of generalized estimand may not always be what we are interested in. 

We will learn to deal with heterogeneous treatment effects in later chapters, however it is worth keeping in mind how assumptions of homogeneity can impact our understanding of treatment effect.--> 

In the train study, all of the individuals surveyed are different in many different ways, for example gender, income, and age. Therefore, our study population is heterogeneous. So far, we have made assumptions that there is a similar treatment effect for all subjects in the study, despite the heterogeneity of our sample.

This assumption is unfortunately rarely true. There will inevitably be some random variation of treatment effect for individuals. The effect on Yao may be different than the treatment effect on another individual who is very similar to Yao. This is one example of a *heterogeneous treatment effect*. 

Another example of a *heterogeneous treatment effect* is when the variation in individual treatments are non-random and correlated with some or multiple factors. For example, maybe we think that the treatment effect varies depending on the sex and age of an individual. In this case, sex, age and treatment status are three characteristics by which treatment effect varies. These variables may interact, impacting our estimate of treatment effect. We call this an interaction effect.

So, a heterogeneous treatment effect can both explain individual variation, as well as variation between groups determined by some other variable(s). 

In the most extreme case, the treatment effect for every individual in our study is different. Our actual Preceptor Table would therefore look like this: 

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Yao", "Emma", "Cassidy", "Tahmid", "Diego"),
       ytreat = c("13", "11", "$$10 + \\tau_{cassidy}$$", "$$12 + \\tau_{tahmid}$$", "5"),
       ycontrol = c("$$13 - \\tau_{yao}$$", "$$11 - \\tau_{emma}$$", "10", "12", "$$5 - \\tau_{diego}$$"),
       ydiff = c("$$\\tau_{yao}$$", "$$\\tau_{emma}$$", "$$\\tau_{cassidy}$$", "$$\\tau_{tahmid}$$", "$$\\tau_{diego}$$")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  cols_move(columns = vars(ytreat, ycontrol), after = vars(subject)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol)) %>%
  tab_spanner(label = "$$\\text{Estimand}$$", vars(ydiff)) %>%
  fmt_markdown(columns = TRUE)
```

Can we solve for just $\tau_{yao}$. No! That is the Fundamental Problem of Causal Inference. So how can we make any progress from here if we are unwilling to assume there is at least some structure to the causal effect across different individuals?

We might not be able to solve each individual's value for $\tau$, but we are not completely stuck. 

<!-- Explain how this is true for both predictive and causal models. First introduction to this contrast. Write a couple paragraphs, drawn from themes.Rmd.  -->
 
<!-- We may not just be interested in the effect on Yao, a person in our sample, but on Eliot, for whom we observe neither potential outcome.  Even if we have a good estimate of the ATE for *this sample*, it may be a bad estimate of the ATE for the *population* if not all people have the same chance of being included in our sample.  So reducing our uncertainty about Yao may still not answer the question we really care about. There is still a lot of missing data. -->

### Average treatment effect

The average treatment effect is the **average** difference in *potential* outcomes between the treated group and the control group. The difference between this estimand and estimands like $\tau$, $\tau_M$ and $\tau_F$, is that in this case we do not care about using the average treatment effect to fill in missing values in each row. The average treatment effect is useful because we don't have to assume anything about each individuals' $\tau$, like $\tau_{yao}$, but can still understand something about the average causal effect across the whole sample. 

`r margin_note("Note that this is the exact process we used to find an estimate for $\\tau$ when we assumed there was a constant treatment effect for everyone in the study.")`

As we did before, the simplest way to estimate the ATE is to take the mean of the treated group ($9.67$) and the mean of the control group ($11.0$) and then take the difference in those means ($-1.33$). We'll call this estimate of the average treatment effect, $\widehat{ATE}$, pronounced "ATE-hat."

If we already did this exact same calculation above, why are we talking about it again? Remember that we unwilling to assume treatment effect is constant in our study population, and we cannot solve for $\tau$ if $\tau$ is different for different individuals. This is where $\widehat{ATE}$ is helpful. 

*Some* estimands may not require filling in all the question marks in the Preceptor Table. We can get a good estimate of the *average* treatment effect without filling in every question mark --- the average treatment effect is just a single number. `r margin_note("$\\widehat{ATE}$ is a function of multiple rows, and does not need to be applied to each row individually (ie. adding a constant tau to fill in the question marks), to be a relevant estimand.")` Rarely in a study do we care about what happens to individuals. In our case, we don't care about what specifically would happen to Cassidy's attitude if treated. Instead, we care generally about how our experiment impacts people's attitudes towards immigrants. This is why an average estimate, like $\widehat{ATE}$ can be helpful.

As we noted before, this is a popular estimand.  Why?

`r margin_note("An estimator is the math/method necessary to find your estimand of interest.")`
1. There's an obvious *estimator* for this estimand: the difference in *observed* outcomes between the treated group and the control group: $Y_t(u) - Y_c(u)$.

`r margin_note("We will discuss randomization more in depth soon.")`

2. If treatment is *randomly assigned*, the estimator is *unbiased*: you can be fairly confident in the estimate if you have a large enough treatment and control group.

3. As we did earlier, if you are willing to assume that the causal effect is the same for everyone (a big assumption!), you can use your estimate of the ATE, $\widehat{ATE}$, to fill in the missing individual values in your Preceptor Table.

Just because the ATE is often a useful estimand doesn't mean that it *always* is. 

Consider point #3. For example, let's say the treatment effect does vary dependent on sex. For males there is a strong negative effect (-3), but for females there is a smaller positive effect (+1). However, the average treatment effect for the whole sample, even if you estimate it correctly, will be a single negative number (-1.33) (since the negative effect for males is larger than the positive effect for females).  So while our model to estimate the ATE is simple and thus alluring, don't assume that it's always the right model for your problem.

`r margin_note("'Actual ATE' refers to the average treatment effect we would calculate if we knew all potential outcomes. This is of course not possible due to the Fundamental Problem of Causal Inference, however we will pretend we know in order to highlight potential problems with estimating ATE.")`

<!-- DK: Stick in the formula for estimating ATE. -->

So estimating the ATE is easy.  But is our $\widehat{ATE}$ a good estimate of the actual ATE?  After all, if we knew all the missing values in the Preceptor Table, we could calculate the ATE perfectly.  But those missing values may be wildly different from the observed values.  Consider this unobservable ideal Preceptor Table:

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Yao", "Emma", "Cassidy", "Tahmid", "Diego"),
       ytreat = c("13", "11", "12", "14", "5"),
       ycontrol = c("11", "9", "10", "12", "3"),
       ydiff = c("+2", "+2", "+2", "+2", "+2")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  cols_move(columns = vars(ytreat, ycontrol), after = vars(subject)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol)) %>%
  tab_spanner(label = "$$\\text{Estimand}$$", vars(ydiff)) %>%
  fmt_markdown(columns = TRUE)
```

`r margin_note("'This inferential process is most directly conceptualized as finding the probability distribution of missing values given observed values and scientific assumptions, i.e., formally, finding the posterior predictive distribution of the missing values, whence the posterior distribution of the estimands can be calculated. ... The approach of distributionally filling in (or multiply imputing) the missing values is intuitive and reveals the natural uncertainty of inference.' ^[Rubin 2011]")`

```{r echo=FALSE, fig.margin=TRUE}
knitr::include_graphics("03-rubin-causal-model/images/beginningofchaptermeme.jpg")
```
In this example, there is indeed a constant treatment effect for everyone: $+2$. Note that the *observed* values are all the same, but the unobserved values were such that our estimated ATE, $-1.33$, is pretty far from the actual ATE, $+2$. We'll consider in a little bit when it is reasonable to assume that our estimate of the ATE is a good one. If we think we have a reasonable estimate of ATE, using that value as a constant for $\tau$ might be our *best guess* if we do want to estimate the counterfactual for an individual. For more discussion, see this video:

`r margin_note("We cannot individually know each person's $\\tau$ because of the Fundamental Problem of Causal Inference.")`

```{r echo=FALSE, fig.margin=TRUE}
knitr::include_app("https://www.youtube.com/embed/cBYUuD2aVkA")
```

## The Four Cardinal Virtues

The four [Cardinal Virtue](https://en.wikipedia.org/wiki/Cardinal_virtues) are Wisdom, Justice, Courage and Temperance. Since data science is the most moral of professions, we will need to cultivate these virtues as we trod the difficult path toward expertise. We revisit these virtues in almost every chapter going forward. Our guide is not dictionary definitions but lived experience.  

### Wisdom

<!-- Begin with Cardinal Virtue -->

```{r echo=FALSE, fig.margin=TRUE, fig.cap="Wisdom"}
knitr::include_graphics("other/images/Wisdom.jpg")
```

To be wise is to show care and thoughtful discretion with regard for the future. This is important for our understanding of the Rubin Causal Model because we need to decide what data is actually relevant to the problem we want to solve. We have to be wise in how we go from the problem which confronts us to the data which we have access to or might reasonably acquire. 

<!-- DK: Add Tukey quote about burning desire. -->

First we should specifically define what we want to know. In the case of Enos (2014), we probably want to understand people's attitudes toward immigration so that we can understand something else about how they will act in the future, like how they will vote. Yao's attitude at the moment when we survey him is not what really matters. We also probably care about the attitudes of people who were not surveyed. This expands our problem beyond the simple Preceptor Tables we have presented so far.

**Wisdom will be key in making assumptions which reduce the "blooming, buzzing confusion" of the world to something amenable to analysis.**

<!-- DK: Insert William James quote. -->

#### The infinite Preceptor Table

We have discussed the ideal Preceptor Tables (no missing data), actual Preceptor Tables (question marks representing the values we don't know), but there is one more type of Preceptor Table. In the real world, a Preceptor Table has an infinite number of rows, and therefore an infinite amount of missing data. We call this type of Preceptor Table an infinite Preceptor Table. Such a reality is unworkable, so we make assumptions to reduce the true problem to something more manageable.

`r margin_note("Why should we care about Yao's (or anyone's) attitude years from now? We need to consider why we are doing the experiment in the first place. Why would we care about Yao's attitude towards immigrants in the first place? There might be many answers to this question, like wanting to understand how he might vote or treat other people. That would mean we care about Yao's attitude in the future, not just at the time of being surveyed.")`

Let's start by looking at what kinds of missing data make up the infinite Preceptor Table. For example, say we only care about the causal effect of this experiment on Yao. Do we only care about his attitude right after the experiment? No! We also care about Yao's potential outcomes one year from now, two years from now, and so on.

So our full Preceptor Table includes people we know (Yao) and people we don't (for example, Eliot), both now and in the future:

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Yao this year", "Yao next year", "Yao two years from now", "Eliot this year", "Eliot next year", "Eliot two years from now", "...", "Person n at time t"),
       ytreat = c("13", "?", "?", "?", "?", "?", "?", "?"),
       ycontrol = c("?", "?", "?", "?", "?", "?", "?", "?"),
       ydiff = c("?", "?", "?", "?", "?", "?", "?", "?")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  cols_move(columns = vars(ytreat, ycontrol), after = vars(subject)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol)) %>%
  tab_spanner(label = "$$\\text{Estimand}$$", vars(ydiff))
```

```{r echo=FALSE, fig.margin=TRUE}
knitr::include_graphics("03-rubin-causal-model/images/wonderfullifememe1.jpg")
```
In fact, because time is continuous, there is a row for Yao now, Yao one second from now, Yao one day from now and so on. The Preceptor Table extends downward forever. Thus, in order to estimate any causal effect, we need *assumptions*, so we aren't dealing with an infinite table. 

The most obvious way to eliminate some rows from the table is to assume the causal effect for Yao now is the same as all the ones for Yao in the future. Is that plausible? Sort of. Yao now and Yao in one second are pretty similar! Yao now and Yao in 30 years are less so.  Unfortunately, there's no magic way to get a good estimate of every missing value in the infinite Preceptor Table! But through some assumptions, we can reduce the true problem to the problem we were dealing with before. 

Not only can we extend the Preceptor Table by adding people not in our sample to the rows, but we can also add additional treatments to the columns.  Let's go back to the original five people in our sample. What if we also wanted to test the causal effect of another language being spoken on the platform?  We'll call the original treatment $t$ and the new treatment $t'$.

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Yao", "Emma", "Cassidy", "Tahmid", "Diego"),
       ytreat = c("13", "11", "?", "?", "5"),
       ytreat2 = c("?", "?", "?", "?", "?"),
       ycontrol = c("?", "?", "10", "12", "?")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
             ytreat = md("$$Y_t(u)$$"),
             ytreat2 = md("$$Y_{t'}(u)$$"),
             ycontrol = md("$$Y_c(u)$$")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ytreat2, ycontrol)) %>%
  fmt_markdown(columns = TRUE)
```

Note that for Yao, we now have three causal effects we can estimate: the difference between the original treatment and the new treatment, the difference between the original treatment and control, and the difference between the new treatment and control.  And that's just when looking at differences!  Recall there are many other potential estimands we could be interested in, such as ratios, percent changes, and so on.

Even if you have just one language you are testing, there still could be multiple treatments.  For example, the amount of time the commuter is on the platform with the Spanish-speakers might vary across commuters. In that case, each might receive a different treatment.

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Yao", "Emma", "Cassidy", "Tahmid", "Diego"),
       ytreat = c("13", "11", "?", "?", "5"),
       ytreat2 = c("?", "?", "?", "?", "?"),
       ytreat3 = c("?", "?", "?", "?", "?"),
       ytreat4 = c("?", "?", "?", "?", "?"),
       ytreat5 = c("?", "?", "?", "?", "?"),
       ycontrol = c("?", "?", "10", "12", "?")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
             ytreat = md("$$Y_{\\text{1 minute}}(u)$$"),
             ytreat2 = md("$$Y_{\\text{5 minutes}}(u)$$"),
             ytreat3 = md("$$Y_{\\text{10 minutes}}(u)$$"),
             ytreat4 = md("$$Y_{\\text{15 minutes}}(u)$$"),
             ytreat5 = md("$$Y_{\\text{20 minutes}}(u)$$"),
             ycontrol = md("$$Y_c(u)$$")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ytreat2, ytreat3, ytreat4, ytreat5, ycontrol)) %>%
  fmt_markdown(columns = TRUE)
```

Again, there are many possible estimands.  It's worth noting when the treatments have some numeric relationship to each other (in this case time), there may be reasonable assumptions we can use to help fill in the missing values -- but we aren't there yet!

Instead of considering the treatment in terms of duration, we could also consider different volume levels at which Spanish is being spoken. 

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Yao", "Emma", "Cassidy", "Tahmid", "Diego"),
       ytreat = c("13", "11", "?", "?", "5"),
       ytreat1001 = c("?", "?", "?", "?", "?"),
       ytreat1002 = c("?", "?", "?", "?", "?"),
       yellipsis = c("?", "?", "?", "?", "?"),
       ycontrol = c("?", "?", "10", "12", "?")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
             ytreat = md("$$Y_{\\text{Volume 1}}(u)$$"),
             ytreat1001 = md("$$Y_{\\text{Volume 2}}(u)$$"),
             ytreat1002 = md("$$Y_{\\text{Volume 3}}(u)$$"),
             yellipsis = md("$$Y_{\\text{Volume N}}(u)$$"),
             ycontrol = md("$$Y_c(u)$$")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ytreat1001, ytreat1002, yellipsis, ycontrol)) %>%
  fmt_markdown(columns = TRUE)
```

Indeed, there are an infinite number of possible treatments. The Preceptor Table extends to the right forever. Again, assumptions come to our rescue. Or rather, we just throw up our hands and only try to estimate a few things. This is why it is crucial to define one's estimand precisely: if we are interested in the difference in potential outcomes between Spanish being spoken for 10 minutes at a volume level 3 versus control, we can ignore all the other possible columns in the infinite Preceptor Table.

`r margin_note("Remember, an infinite Preceptor Table has an infinite number of rows and columns. Assumptions are what reduce the true problem to a workable problem.")`

Thus, whenever you are considering a causal question, the best way to think about it is to start with the infinite Preceptor Table.  First we throw out the rows we think are duplicates (such as all the observations for Yao one second from now, two seconds from now, etc.) or that are outside the scope of what we are interested in for now (maybe we don't care about outcomes 30 years in the future for this study).  Second, we throw out the columns that we don't care about, which are all the possible treatments we aren't considering.  Finally, we define precisely---in terms of potential outcomes---our estimand.  It may be something simple, such as the average treatment effect, or something more complex.  Once we have done these steps, we can start thinking about how to fill in the question marks.  But remember that the infinite Preceptor Table is always there, and you should be conscious of which rows and columns you are throwing out!

Without Wisdom, the magnitude of the infinite Preceptor Table would be overwhelming. We are acting with care and discretion by making assumptions that allow our future selves to manage the question and data we have.

#### More missing data

Let's look at another example of how being prudent can help us to map a path from our question to the data. As we mentioned previously we likely care about the attitudes of people not surveyed. 

Say that before you run the train experiment, you want to know the average attitude towards immigrants of *all* United States adults. At first, this seems like an easy problem---there's nothing causal here!  If you knew the true values, you could build a data set like this: 

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Person 1", "Person 2", "Person 3", "...", "Person N"),
       `Attitude` = c("13", "11", "9", "...", "10")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "Outcome", vars(`Attitude`))
```

Then, your answer is simply the average of all the values. 

But do we have this table?  No!  What we actually have is this:

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Person 1", "Person 2", "Person 3", "...", "Person N"),
       `Attitude` = c("?", "?", "?", "...", "?")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "Outcome", vars(`Attitude`))
```

In reality, we don't know the attitude towards immigrants of any United States adults. That is, we have a lot of *missing data*.

But maybe we could survey 1,000 people on their attitudes towards immigrants, and get a table that looks like this:

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Respondent 1", "Respondent 2", "Respondent 3", "...", "Respondent 1,000"),
       `Attitude` = c("13", "9", "11", "...", "10")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "Outcome", vars(`Attitude`))
```

By surveying 1,000 people on their attitudes towards immigrants we now have some values to work with. This, however, does not solve the missing data problem. We are likely interested in the causal effect *in general*, not just for our 1,000 person sample. We'll need to think about whether our *sample* is representative of the full population. For the vast majority of US adults we still have no value. This is the second of the two most common sources of missing data: 

1. For the units in our sample, we only see *one* potential outcome
2. For the units outside our sample, we see *no* potential outcome

There are in fact many other potential sources of missing data, like we saw in our infinite Preceptor Table! This missing data problem is what creates the need for statistical inferences. If the data were not missing, inference would not be needed.

Wisdom must be used in order to avoid becoming overwhelmed with the real world, and instead to find solutions that allow us to begin answering some of our questions. 

#### Unobservable data

```{r echo=FALSE, fig.cap="This study was conducted by Barfort, Klemmensen and  Larsen.", fig.margin = TRUE}
knitr::include_graphics("03-rubin-causal-model/images/governors.png")
```
Let's consider a new example experiment to highlight another type of data problem we might encounter. Say we want to know the causal effect of being elected governor on life length. In most states the minimum age requirement to be elected governor is 30. People under the age of 30 have no chance of being elected governor. That means for people less than 30 there is only one possible observable potential outcome. In our actual Preceptor Table, this means we have some rows with 2 columns (people old enough to be elected), and some rows with only 1 column (people too young to be elected).

An actual Preceptor Table for this problem might look something like this: 

```{r echo = FALSE}
tibble(subject = c("Yao", "Dean Khurana", "Cassidy", "Preceptor", "Tahmid"),
       ytreat = c("--", "?", "--", "?", "--"),
       ycontrol = c("?", "?", "?", "?", "?")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol)) %>%
  fmt_markdown(columns = TRUE)
```

For Yao, Cassidy and Tahmid there is no question mark in the treatment column because they have no chance of being elected governor. Often in the real world an actual Preceptor Table might look like this. Some rows have two or more columns, and some have fewer. So where do we go from here?

`r margin_note("Recall that in being prudent we want to be specific and careful in how we define our problem. Here is another example of this virtue being put into action as we map from our concept to the data.")`
We should consider we are actually interested in knowing. In this case, we don't really care what the causal effect is on people who can't possibly be elected governor. `r margin_note("Precision in defining our estimand!")` In other words, we don't care what the causal effect is on the whole population, but rather only a subset of the population. Just like in the case of the infinite Preceptor Table we need to throw out rows by being more specific about our problem. `r margin_note("Keep this governor's example in mind, we will talk about it again!")` Instead of saying we want to know the causal effect of being elected governor, we might specify that we want to know the causal effect for the American population over 30. 

Once we have a defined problem and manageable actual Preceptor Table we can begin to deal with all those question marks. 

### Justice 

```{r echo=FALSE, fig.margin=TRUE, fig.cap="Justice"}
knitr::include_graphics("other/images/Justice.jpg")
```

Justice is often compared to fairness and seeking moderation. In data science we will take this to mean making sure our model structures match reality enough; that they are "fair" and as unbiased as possible.

**We want to make sure our models are as just and representative of the real world as possible.**

#### The assignment mechanism

We will start with the assignment mechanism as an example of when Justice is necessary. A biased assignment mechanism will ruin any chance for our model to be fair in its representation of reality.

Remember that *everything is a missing data problem*.   We sidestepped the following question before: Is the difference in sample means between treated units and control units, $\widehat{ATE}$, a good estimate of the ATE?  That depends entirely on the method by which units are assigned treatment, which is called the **assignment mechanism**.  That is the mechanism whereby some values are missing and some values are observed.

As we discussed earlier, this already comes up in non-causal context when considering *sampling*. If we are trying to estimate the average attitude towards immigrants in the U.S., we usually do so by taking a sample. The process by which people enter our sample is called the *sampling mechanism*. If the process by which people enter our sample is related to their attitude, even indirectly, then estimates from our sample won't be good estimates for the population.

The sampling mechanism still matters in causal inference.  You may want to estimate the causal effect for Eliot, for example, rather than Yao.  But before you even get to the sampling mechanism, there is another missing data problem that can affect causal inference.  That is the *assignment mechanism*, the process by which some units receive treatment and others do not. It will soon be clear why randomization is the ideal assignment mechanism. Whenever the assignment mechanism is correlated with the potential outcomes, we say that there is **confounding**. Confounding is a problem, since it means that our simple estimate of the ATE is biased.

If you are interested in causal inference, randomized trials are the best approach. In many circumstances, however, randomized trials are not possible due to ethical or practical concerns. In such scenarios there is by necessity a non-random assignment mechanism. The following example of a non-random assignment mechanism illustrates potential problems.

For instance, let’s say you were interested in the effect of college attendence on earnings. People are not randomly assigned to attend college. Rather, people may choose to attend college based on their financial situation, parents’ education, and so on. This can introduce confounding if the assignment mechanism affects future earnings. For example, if people choose to go to college at higher rates when they are on career paths where a college degree is particularly beneficial – or, in RCM language, whose potential outcomes are on average higher under treatment – that would introduce confounding.

Let's look at this idea of a non-random assignment mechanism through a version of the train experiment. Say that one platform has both control and treatment regions. The Spanish-speakers would be randomly assigned to regions, and only people within that region would be considered treated. The travelers however are not randomly assigned to a region, and are permitted to move freely on the platform. Despite the random assignment of regions on the platform there still may be confounding. Say that people who have conservative attitudes towards immigrants are hyper-aware of the Spanish being spoken, and therefore choose to stand in the treated regions. This would shift the average attitude of the treated regions higher. It would therefore seem as though the treatment makes people more conservative, when in reality there is bias in the assignment mechanism despite the randomization of regions. From this example, it is clear that when looking at new data, even if it is seemingly randomized, it is important to consider the ways in which there still may confounding. 

Assignment mechanisms can also intentionally be biased in order to manufacture desired outcomes.
`r margin_note("Consider the case of a 'perfect doctor', who knows exactly how a certain drug will impact his patients. He would only give the drug to patients who benefit from the it. This would make the drug seem very beneficial. In reality half of his patients who never took the drug (control group) would have been harmed by taking it.")`
Let's consider a scenario where once again an entire platform is either treated or a control. In this case the assignment mechanism is the choice of the Spanish-speakers; they are allowed to choose which platform they want to stand on. Let's also say that they can *perfectly* predict the attitude of people on each platform. The Spanish-speakers know that a platform with more liberal attitudes towards immigrants will be more friendly, and therefore always choose to stand on those platforms. In this case, the assignment mechanism of platforms is not random. The Spanish-speakers know these averages for the various platforms in the experiment: 

`r margin_note("The ATE in this case is +0.5.")`
```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Platform 1", "Platform 2", "Platform 3", "Platform 4", "Platform 5", "Platform 6"),
       ytreat = c("14", "7", "5", "13", "4", "13"),
       ycontrol = c("10", "6", "8", "12", "6", "11"),
       ydiff = c("+4", "+1", "-3", "+1", "-2", "+2")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  cols_move(columns = vars(ytreat, ycontrol), after = vars(subject)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol)) %>%
  tab_spanner(label = "$$\\text{Estimand}$$", vars(ydiff))
```

`r margin_note("The Spanish-speakers in the experiment will choose to stand on the more liberal platforms because they know those platforms are friendlier on average. This assigns the more liberal platforms as 'treated' in this scenario.")`
Based on this knowledge the Spanish-speakers in the experiment would choose the following treatment assignments: 
`r margin_note("The estimated ATE in this example would be -5.67.")`

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Platform 1", "Platform 2", "Platform 3", "Platform 4", "Platform 5", "Platform 6"),
       ytreat = c("?", "7", "5", "?", "4", "?"),
       ycontrol = c("10", "?", "?", "12", "?", "11"),
       ydiff = c("?", "?", "?", "?", "?", "?")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  cols_move(columns = vars(ytreat, ycontrol), after = vars(subject)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol)) %>%
  tab_spanner(label = "$$\\text{Estimand}$$", vars(ydiff)) 
```

The assignment mechanism used distorts the averages of both $Y_t(u)$ and $Y_c(u)$, which in turn distorts the difference in means. The average of the treated group is shifted lower (more liberal), while the average of the control group is shifted higher (more conservative). This gives the illusion that the average treatment effect $\widehat{ATE}$ is negative. The true positive causal effect is masked by this non-random assignment mechanism. 

`r margin_note("This estimate for ATE in this example is -5.67, which is very far from the actual ATE which is  +0.5.")`

Therefore, the difference in means is no longer a good estimate of the ATE. In fact, in this case it has the wrong sign! This is not merely a consequence of our small sample: even if there were a million platforms in the experiment, we could not get a good estimate of the ATE.

<!-- EC: Could be a good place to introduce type S errors to tie in to a future chapter on Type M/S errors (unsure which this would be) -->

This is an extreme example of a problem called **selection bias**. `r margin_note("Selection bias is when the person who is assigning treatment chooses on the basis of potential outcomes.")` The Spanish-speakers are not choosing platforms to stand on randomly. Rather, they are making treatment decisions based directly on the potential outcomes of each platform. Remember, whenever the assignment mechanism is correlated with the potential outcomes there is confounding, which is a problem because it means that our estimand is biased. Not all examples of confounding are caused by selection bias, but when there is selection bias there is *always* confounding

Much like how the best way to avoid making poor inferences from a sample to a population is to take a random sample of the population, the best assignment mechanism for avoiding confounding is **randomization**. For each platform we could flip a coin to determine if it is in the treatment or control group.

Randomized assignment is the best assignment mechanism for inferring the average treatment effect because if the sample is large enough, the difference in sample means between treated and control units ($\widehat{ATE}$) will be very close to the actual ATE from that sample. `r margin_note("'actual ATE' in this case would be the ATE you could calculate if you were omniscient and knew all potential outcomes, which is of course impossible.")` (You still can't know *individual* treatment effects without more assumptions, because of the fundamental problem of causal inference.)

Randomized assignments don't all look the same. For example, randomized block assignment is a method of random assignment that can be useful in further reducing potential confounding, making it an even better estimator than pure random assignment. In random block assignment, subjects in an experiment are subdivided into blocks. The assignment into blocks is not random, instead there is intentionally less variation within blocks than there is between them. Within those blocks subjects are randomly assigned to treatment or control. 

For example, let's use a method of random block assignment with our train study. For example, we might think that there are systematic differences between platforms that might impact the treatment effect. Instead of randomly assigning platforms as control or treated, we could use random block assignment. Each platform would be a block. We could then randomly assign half of the individuals in each block (platform) as control (section of the platform with no Spanish-speakers), and the other half as treated (section of the platform with Spanish-speakers). The resulting random assignment would look something like this: 

```{r, echo = FALSE}
# Create tibble to show what block randomization would look like

tibble(platforms = c("Platform 1", "Platform 2", "Platform 3"),
       control = c("25", "25", "25"), 
       treated = c("25", "25", "25")) %>%

# Use gt to make it pretty
  
gt() %>%
  cols_label(platforms = "Blocks",
                control = "Control",
                treated = "Treated") %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(platforms))) %>%
  tab_style(cell_text(weight = "bold"),
            location = cells_body(columns = vars(platforms))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle"), 
            locations = cells_column_labels(columns = vars(platforms))) %>%
  cols_align(align = "center", columns = TRUE)
```

Block random assignment ensures that both treated and control groups have an equal proportion of individuals from each platform. This assignment mechanism is a way to remove differences between platforms as a potential source of variability, and therefore minimizing a potential source of confounding. Individuals within each block are still randomly assigned, so this is just an example of a different way to use random assignment. 

If you are interested in causal inference, randomized trials are the best approach. In many circumstances, however, randomized trials are not possible due to ethical or practical concerns. In such scenarios there is by necessity a non-random assignment mechanism.

For example, let's say some of the train platforms in the experiment are so loud the Spanish-speakers might not be heard by anyone nearby. Therefore by necessity, only quieter platforms can be assigned to the treatment group. This non-random assignment may introduce confounding. `r margin_note("Maybe the louder platforms have people that are generally more friendly and social. This might be correlated with more liberal attitudes towards immigrants.")` Say there is some systematic difference between the people on quieter platforms compared with the people on the louder platforms. In that case, the assignment mechanism is correlated with potential outcomes, so there is confounding. This means even a simple estimand like ATE would be biased. 

Many statistical methods have been developed for causal inference when there is a non-random assignment mechanism, such as propensity score matching. These methods attempt to correct for the assignment mechanism by finding control units similar to treatment units.  What you should not do is naively compare the sample means under treatment and control and assume that is a good estimate of the ATE.  Without randomization, this could be very misleading!

Now, let's consider our Preceptor Table for Yao, Emma, Cassidy, Tahmid, and Diego again:

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Yao", "Emma", "Cassidy", "Tahmid", "Diego"),
       ytreat = c("13", "11", "?", "?", "5"),
       ycontrol = c("?", "?", "10", "12", "?"),
       ydiff = c("?", "?", "?", "?", "?")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  cols_move(columns = vars(ytreat, ycontrol), after = vars(subject)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  fmt_markdown(columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol)) %>%
  tab_spanner(label = "$$\\text{Estimand}$$", vars(ydiff)) 
```

Let's say random assignment into treatment was used to get these values.  If that is the case, our estimate $\widehat{ATE} = -1.33$ is an *unbiased* estimate of the ATE.  So why don't we just always use randomized assignment and assume an unbiased estimand? Even if randomization is the best assignment mechanism it is not always perfect.

#### Scale

In our train example, the accuracy of our scale will impact the fairness of our model, yet another example of when practicing Justice in creating our model is necessary. 

In the train example, a scale is being used to understand attitude towards immigrants of subjects in the study. The scale goes from 3 (most liberal) to 15 (most conservative). As we discussed earlier, one way of filling in the missing data is by using $\tau$ which let's assume is the same for all subjects in our study, and is $-1.33$.

Say Jessica and Miro are subjects in our study for which we want to fill in the missing values.  

``` {r, echo = FALSE}
tibble(subject = c("Jessica", "Miro"),
       ytreat = c("?", "?"),
       ycontrol = c("3", "15"),
       ydiff = c("-1.33", "-1.33")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  cols_move(columns = vars(ytreat, ycontrol), after = vars(subject)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol)) %>%
  tab_spanner(label = "$$\\text{Estimand}$$", vars(ydiff)) %>%
  fmt_markdown(columns = TRUE)
```

`r margin_note("'Then we should think about the mechanism that led to observed values being observed and unobserved values being missing. To me, statistical inference concerns estimating missing values from observed values rather than pondering p-values, and one cannot even begin to do this without assuming something about the process that created the missing values: was it, for example, simple random sampling or was it a censoring mechanism? ... We should not avoid discussing the scientific context of any statistical problem, because this can greatly affect the resulting inference.' ^[Rubin 2011]")`

For Miro it is easy, we would estimate his treated attitude to be $13.67$. For Jessica things seem to get more complicated. Our scale does not go below 3, so an estimated control attitude of $1.67$ doesn't make any sense. We would have the same issue for Miro if the $\tau$ we were using to fill in values was positive. This highlights a potential issue that can arise when using a scale, which is **censoring**. Censoring in statistics is when the value of a measurement is only partially known. In this case, Jessica might have an attitude score of 3, which we understand as the most liberal on our scale. In reality her attitude may be more liberal than is possible to capture with our survey scale. So, we only partially know her attitude. We know it is very liberal, but we don't have any sense of if it is more liberal than our scale allows for, or by how much. 

Ideally, we want everyone's attitude scores to fall somewhere in the middle of our scale so we don't have this issue of censoring. If a large percentage of our subjects have an attitude score on one extreme or another of our scale, this would give us an idea that our scale likely needs to be adjusted. 

#### Causal vs. Predictive Models

Causal inference is often compared with prediction.  In prediction, we want to know an outcome, $Y(u)$.  In causal inference, we want to know a function of *potential* outcomes, such as a treatment effect $Y_t(u) - Y_c(u)$.

Note, however, that these are both kinds of missing data problems.  Prediction involves getting an estimate for an outcome variable that we don't have, and thus is missing, whether because it is in the future or because it is from data that we are unable to collect.  Thus, prediction is the term for using statistical inference to fill in missing data for outcomes.

Causal inference, however, is the term for filling in missing data for potential outcomes.  Unlike with prediction, only one potential outcome can *ever* be observed, even in principle.  (If you are forecasting the weather, you can compare your forecast from yesterday to the actual weather today.)  In a way, however, this is still a kind of prediction: it is just a prediction about a quantity you can't ever observe (a potential outcome).

In both causal inference and prediction, the process by which some data is missing and some is observed is crucial.  If we think that the missing data is similar to the observed data, we can make inferences more easily.  If not, we have to think through the dissimilarities and consider how to model them.

We should also further discuss the subtleties that differentiate predictive and causal models.

Remember that  in a predictive model all we care about is forecasting some value $Y(u)$ given that we know $X$. This means we only have one column of outcomes for each value $X$. Let's continue using the train example, and say that $X_1$ is being under 50 years old, and $X_2$ is being 50 or older. 
Let's see what this would look like in a Preceptor Table:

``` {r, echo = FALSE}
tibble(x = c("Under 50", "50 and Over"),
       y = c("9.21", "9")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(x = md("$$\\mathbf{X}$$"),
                y = md("$$Y(u)$$")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(x))) %>%
  tab_style(cell_text(weight = "bold"),
            location = cells_body(columns = vars(x))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  fmt_markdown(columns = TRUE)
```

In this model, given someone is under 50 years old we would predict a $Y(u)$ value of $9.21$. Similarly, $9$ would be the prediction given $X$ is someone over 50 years old. We have made strong assumptions to create this predictive model and should be aware of the implications of those assumptions. Do we think the predictions we could make using this model are realistic? Probably not. But hopefully from this example the differences between predictive and causal models may be a little more clear.

An important distinction to notice is that there is only one $Y(u)$ value for each $X$. This is very different to the RCM we are used to where there are two potential outcomes (treated and control). There is only one outcome column in a predictive model, whereas there are two or more in a causal model.

With a predictive model we cannot infer what would happen to the outcome $Y(u)$ if we changed $X$. This is also different to what we are used to from a causal model where we are trying to understand the causal effect of some change (treatment). From our predictive model, we can compare the two groups and note that we would predict people under 50 to have an attitude score slightly more conservative than those 50 and over. We cannot claim, however, that we understand what would happen to an individual's attitude once they turn 50 (confounding!). Similarly, we cannot make any estimate of what an individual's attitude might have been when they were under 50 years old. As you will soon read about, age is not something we can ever estimate a causal effect for.

In a sense, all models are predictive. If we had more data from a stable distribution, then we could make a predictive forecast of someone's attitude. Only a subset of models are causal, meaning that, for a given individual, you can change the value $X$ and observe a change in outcome, $Y(u)$, and from that calculate a causal effect.

We should employ Justice in discussing the type of model we use to answer a question. There are critical differences between causal and predictive models that can be overlooked if one is not precise and just in describing the models they have used. 

#### Mathematical Models

Let's represent the problems we have been discussing throughout this chapter in a mathematical model: 

$$outcome = model + what \ is \  not \ in \ the \ model$$

We have an outcome, which we can represent with our model plus the unmodeled variation that riddles the real world. Using a model we create, we are able to come up with a best guess for an outcome we would like to predict. If we are appropriately applying Justice to our understanding of a problem, we recognize that we are limited by all the variation that is not represented in our model. 

Let's now apply our train problem to a mathematical model. The outcome we are interested in is the attitude of an individual, $attitude(i)$. Let's assume again that there is a constant treatment effect, $\tau$, for everyone. We will also define treatment status numerically, with 0 being control and 1 being treated. We can predict $attitude(i)$ by adding $\tau$ * treatment status (either 0 or 1) with the average of all the control values we already have ($avg(Y_c(u))$). If we are predicting the attitude if control for an individual, we add $\tau$ * 0 because our best guess would just be the average of all control values. If we are predicting the attitude if treated of an individual, we want to add the value of tau to the average of controls. This distinction is why we numerically define control and treated statuses as 0 and 1 respectively.

$$ attitude(i) = avg(Y_c(u)) + (\tau * treatment \ status)  + unmodeled \ variation$$
`r margin_note("Recall the discussion on heterogenous treatment effects.")`
Once again, Justice is necessary when representing our model. The unmodeled variation that we cannot predict is what makes our best guess different from the true attitude of an individual which is impossible to observe. 

### Courage


Courage is synonymous with fortitude, forbearance, strength and endurance --- the ability to confront fear, uncertainty and intimidation.

```{r echo=FALSE, fig.margin=TRUE, fig.cap="Courage"}
knitr::include_graphics("other/images/Courage.jpg")
```

The three languages of data science are words, math and code, and the most important of these is code. We need to explain the structure of our model using all three languages. Courage is important in helping us to create the *data generating mechanism* via code. 

**We need *Courage* to implement the model in code.**

#### More complex models for causal inference

In this chapter, we explained that there are many possible causal estimands that may be of interest, discussed one in greater detail (the ATE), and provided an estimator for that estimand---the difference in means between treatment and control, which we called $\widehat{ATE}$.  But more complex models can help both with estimating the ATE and with estimating more complex estimands.

We will cover these topics more when we discuss regression and other models, but moving beyond a simple difference in means can help a lot with causal inference:

1. More complex models can help correct for non-random treatment assignments, if the factors that lead to treatment assignment are known.
2. More complex models can also help with estimating different treatment effects for different groups.  Recall we discussed the possible assumption that are different treatment effects for Democrats and Republicans, $\tau_1$ and $\tau_2$.  While you could just calculate the difference in means for each group, that may lead to small sample sizes, especially if there are a lot of groups.  More complex models can help *pool* information across groups to get better estimates. 
3. Finally, the difference in means doesn't work with continuous treatments, such as taking Spanish being spoken at Volume level 3 or Volume level 4. `r margin_note("We look at this in later chapters.")` Regression and other models can handle continuous treatments much better.

You will need a lot of fortitide when learning about these more complex models in future chapters!

### Temperance 

<!-- also known as restraint, the practice of self-control, abstention, discretion, and moderation tempering the appetition. -->

Temperance is the practice of self-control, discretion and moderation.

```{r echo=FALSE, fig.margin=TRUE, fig.cap="Temperance"}
knitr::include_graphics("other/images/Temperance.jpg")
```

Temperance is the most important virtue in data science. Your models are never as good as they appear to be. The world is complex and, even worse, always changing. We cannot ignore the uncertainty and unmodeled variation that come along with inference. 

**We need to have Temperance to recognize the limitations of our models.**

#### Uncertainty

Let's return to our sample of five people, and an assumption that there is a constant treatment effect of -1.33 for all of them. Recall our Preceptor Table that looked like this: 

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Yao", "Emma", "Cassidy", "Tahmid", "Diego"),
       ytreat = c("13", "11", "8.67", "10.67", "5"),
       ycontrol = c("14.33", "12.33", "10", "12", "6.33"),
       ydiff = c("-1.33", "-1.33", "-1.33", "-1.33", "-1.33")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  cols_move(columns = vars(ytreat, ycontrol), after = vars(subject)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol)) %>%
  tab_spanner(label = "$$\\text{Estimand}$$", vars(ydiff)) %>%
  fmt_markdown(columns = TRUE)
```

In general, do we think that if Yao wasn't on the platform with Spanish-speakers, his attitude toward immigrants would be exactly $14.33$? Of course not! We have some uncertainty around these numbers.  There are two main sources of uncertainty we have to take into account when making a prediction for Yao: 

<!-- CB: Is parameter uncertainty only the first example here? I am having trouble being certain about what is parameter uncertainty and what is just uncertainty?  -->

1. `r newthought("Uncertainty in estimating the ATE.")` Even if treatment is randomly assigned, and thus $\widehat{ATE}$ is an unbiased estimate of ATE, we still may not have a very precise estimate if our sample is small. With this miniscule sample (five subjects!), the uncertainty might be gigantic, perhaps something like $(-3, 2)$, which would lead to a prediction for Yao of $(10, 15)$. As we get a larger sample size, this uncertainty decreases.  -->

`r margin_note("Remember the section on heterogenous treatment effects!")`
2. `r newthought("Individual Variation.")` Even if we have a perfect estimate of the *average* treatment effect, it still may be the case that the effect *for Yao* is higher or lower than the average. We can assume this away if we say that the treatment effect is a constant $τ$ for everyone, but that is not likely to be true in the real world -- and this source of uncertainty does not go away simply by collecting more observations. So with a large sample, let's say that we calculated a confidence interval around $\widehat{ATE}$ of $(-1.66, -1)$, leading to an interval for Yao's outcome under control of $(14.66, 14)$. The uncertainty due to individual variation may still be a great deal greater -- say $(13, 15)$. These numbers are simply illustrative, but they highlight an important point: even if you have a good estimate of the ATE, you should still be much more uncertain about the causal effect for any *particular individual*. 

The main takeaway is that we can get rid of #1 by collecting more data, but the only way to get rid of #2 is through making assumptions, potentially very strong ones. Later in the book we will look at ways to estimate parameter uncertainty more closely, but for now it is worth keeping different sources of uncertainty in mind.

#### When randomization fails

```{r echo=FALSE, fig.margin=TRUE}
knitr::include_graphics("03-rubin-causal-model/images/randomizationmeme.jpg")
```

We need even more Temperance in situations where randomization, the preferred assignment mechanism, is impossible.

Let's discuss an example. Recall the study about being elected governor and longevity. Being elected governor is not a random process, so it is impossible to have a random assignment mechanism in this case. Is it therefore impossible to find a reasonably unbiased estimate for causal effect? No! We just have to use a different method, and as always be aware of the assumptions we make. 

```{r echo=FALSE, fig.margin = TRUE}
knitr::include_graphics("03-rubin-causal-model/images/regressiondiscontinuitydesign.png")
```

One example of another method we may use when randomization is impossible is called a *regression discontinuity design*. In a regression discontinuity design, there is a sharp cutoff between treatment and control. For our example, this cutoff is winning or losing the governor's election by a small margin. This means that for the governor's example we only use election data in which the position was won by a very narrow margin. By using elections in which the winning margin was so small we can consider this assignment mechanism nearly random. The assumption is that the candidates that fall on the winning side of the cutoff could have just as easily fallen on the loosing side of the cutoff. 

Therefore, the counterfactual for the governors who won their elections narrowly are the governors who lost theirs narrowly.

```{r echo = FALSE}
tibble(ytreat = "Governors who won narrowly",
       ycontrol = "Governors who lost narrowly") %>%
  
  # Then, we use the gt function to make it pretty
  
gt() %>%
  cols_label(ytreat = md("$$Y_t$$"),
                ycontrol = md("$$Y_c$$")) %>%
  cols_align(align = "center", columns = TRUE) %>%
  tab_spanner(label = "Outcomes", vars(ytreat, ycontrol)) %>%
  fmt_markdown(columns = TRUE) %>%
  tab_style(cell_text(size = "large"),
            locations = cells_column_spanners("Outcomes"))
```

Why would it not make sense to just use all governor election data? Because in elections that were won by a lot we could not consider the assignment mechanism (being elected governor) even close to almost random.

Although true randomization was impossible in this example, we can still find estimates for causal effect. Through this process, however, we have made a lot of strong assumptions. Is our interpretation of the data misleading because of the assumptions we made?

Randomization can also fail even when it is possible to randomize the assignment mechanism. 

#### Internal and external validity

Recall the two main sources of missing data:

1. For the units in our sample, we only see one potential outcome
2. For the units outside our sample, we see *no* potential outcomes

If we have randomized assignment and a large sample, we can be confident that we have a good estimate of the average treatment effect *in that sample*.  We say that the experiment has high **internal validity**: the inferences we are making are likely to reflect the truth about that sample.  That reflects the first main source of missing data. `r margin_note("We still need more assumptions if we are interested in more difficult estimands within the sample, such as individual treatment effects.")`

However, we may be interested in a population beyond our particular sample, the second main source of missing data.  For example, let's look at the broader context of the train experiment. You likely are not exclusively concerned about the attitudes of people who ride trains, but rather the attitudes of a larger population. Train platforms, however, are a valuable setting in which to run the experiment.  Let's say that we ran a randomized experiment with 10,000 people in Boston, and found an $\widehat{ATE} = -1.33$. Should we assume this estimate would be accurate for a larger general population?

The answer to that question depends in part on the **external validity** of the study. Are the 10,000 people in the study similar to the people who we want to generalize the findings to? Perhaps we want to generalize to train commuters in other cities. Let's say that the 10,000 people in Boston all choose to ride trains for environmental reasons. That's another form of **selection bias**. The sample is not randomly selected from the population in which we are interested.  Why is that a problem?  Those people differ systematically from other people in a way that may affect their response to the experiment. For example, their preference of public transportation for environmental reasons may be correlated to other political beliefs.

Note that this concern can be expressed in terms of the assignment mechanism.  People who don't ride the train have a 0% chance of receiving the treatment.  Thus, the study *can't* directly speak to how the treatment would impact their attitudes towards immigrants. The only way we can make such claims is by making additional assumptions, such as that train-riders reflect the same makeup of political beliefs as people who don't ride trains.

The external validity of a study is often directly related to the *representativeness* of our sample. Representativeness has to do with how well our sample represents the larger population we are interested in generalizing to. Does Enos' train experiment allow us to calculate a causal effect for people who commute by cars? Can we calculate the causal effect for people in New York City? Before we generalize to broader populations we have to consider if our experimental estimates are applicable beyond our experiment. Maybe we think that commuters in Boston and New York are similar enough, that our $\widehat{ATE}$ also is a good estimate for the causal effect of our treatment in NYC. We could also conclude that people who commute by car are fundamentally different than people who commute by train. If that was true, then we could not say our estimate is true for all commuters because our sample does not accurately represent the broader group we want to generalize to. 

The circumstances of the experiment may also affect the external validity of the study. Perhaps the train study was conducted during the middle of the summer when platforms are uncomfortably hot. Then, while we have variation in one aspect of the treatment (whether there were Spanish-speakers nearby), we don't have variation in another (temperature of train platform). It may be that attitude towards immigrants is impacted when the train platform is uncomfortably hot, but the treatment has no impact on attitude otherwise.

When dealing with human subjects, there is a particular concern regarding external validity: the [**Hawthorne effect**](https://en.wikipedia.org/wiki/Hawthorne_effect).  When human subjects know that they are part of an experiment, they may change their behavior.

In this example, the Hawthorne effect can impact attitudes expressed on surveys. Maybe respondents are more extreme in their attitude in either direction (more liberal or more conservative) because the survey is an opportunity to express opinion. 

We should always be aware of the "realism" of the model. When we look to extrapolate our data beyond the scope of a study, Temperance should always be employed. 

## Other issues with causal inference

`r margin_note("Think about how the cardinal virtues can be applied to your understanding of these other issues involving causal inference.")`

### No causation without manipulation

In order for a potential outcome to make sense, it must be possible, at least *a priori*. For example, if there is no way for Yao, under any circumstance, to ever be in the train study, then $Y_{t}(u)$ is impossible for him. It can never happen. And if $Y_{t}(u)$ can never be observed, even in theory, then the causal effect of treatment on Yao's attitude is undefined. 

The causal effect of the train study is well defined because it is the simple difference of two potential outcomes, both of which might happen. In this case, we (or something else) can manipulate the world, at least conceptually, so that it is possible that one thing or a different thing might happen.

This definition of causal effects becomes much more problematic if there is no way for one of the potential outcomes to happen, ever. For example, what is the causal effect of Yao's height on his weight? It might seem we would just need to compare two potential outcomes: what would Yao's weight be under the treatment (where treatment is defined as being 3 inches taller) and what would Yao's weight be under the control (where control is defined as his current height).

A moment's reflection highlights the problem: we can't increase Yao's height. There is no way to observe, even conceptually, what Yao's weight would be if he were taller because there is no way to make him taller. We can't manipulate Yao's height, so it makes no sense to investigate the causal effect of height on weight. Hence the slogan: *No causation without manipulation.*

This then raises the question of what can and cannot be manipulated. If something cannot be manipulated, we can't consider it causal. So can race ever be considered causal? What about sex? A genetic condition like color-blindness? Can we manipulate these characteristics? In the modern world these questions are not simple. 

Take color-blindness for example. Say we are interested in how color-blindness impacts ability to complete a jig-saw puzzle. Because color-blindness is genetic some might argue it cannot be manipulated. But advances in technology like gene-therapy might allow us to actually change someones genes. Could we then claim the ability to manipulate color-blindness? If yes, we could then measure the causal effect of color-blindness on ability to complete jig-saw puzzles.

The problem is still very complicated even if we can manipulate genes. Gene therapy is not straight forward. Genes interact with each other in ways that scientists are still trying to understand. It is unlikely the gene that controls color-blindness could be manipulated in isolation. Again, these questions are very complicated and don't have clear answers.

Take another example of an experiment where race is "manipulated" on resumes by changing names. Social scientists have studied how names can signal race, so this might seem like a reasonable way to manipulate race. The problem is a name might signal race, but race isn't as simple as a name. In that case, what causal effect are you really studying? It is not just 'names', because you are choosing names based on their ability to signal race. You also are not just manipulating race, because race is not solely determined by having a certain name.  

`r margin_note("An example of Justice is thinking very critically about what is causal and what is not. Is your model actually causal or only predictive?")`
The slogan of "No causation without manipulation" may at first seem straight forward, but it is clearly not so simple. Questions about race, sex, gender and genetics are very complex and should be considered with care. 

### Other solutions to the Fundamental Problem of Causal Inference 

The Fundamental Problem of Causal Inference is that it is impossible to observe two potential outcomes at once, which means one or more potential outcomes are always missing (counterfactuals). Throughout this chapter we use a statistical solution to the Fundamental Problem. We accept the fact that we cannot observe some potential outcomes, and instead use techniques to understand causal effects despite some missing data. 

Other solutions to the Fundamental Problem are commonly used in hard sciences (think chemistry and biology labs). It is still impossible to observe more than one potential outcome *at once*, however, assumptions of homogeneity allow someone to believe they can observe both potential outcomes. 

For example, say you wanted to know the causal effect of an acid on a piece of metal. In a chemistry lab, you might go about understanding this causal effect in two ways. One way would be to measure some variable about a piece of metal before you put it in acid, and then measure that same piece of metal again after you've put it in acid. That would give you the two potential outcomes (control - before acid, treated - after acid) from which you could calculate a causal effect. Although this may seem straight forward, you are making still assumptions which allow you to believe this is a reasonable experiment. You are assuming the piece of metal is fairly static, nothing is changing about it from one moment to the next. You are likely also working to control other variables in the environment (like temperature) to support your assumption of homogeneity. Even if the assumptions you make are valid, they are still assumptions. Another method often used in hard sciences is assuming homogeneity between units. In this experiment, that would look like using two very similar pieces of metal to be both control and treated. You could then calculate causal effect through direct comparison. There is an assumption that the two pieces of metal are similar enough that the only difference between them is if they are treated or not. 

This solution to the Fundamental Problem using assumptions of homogeneity have been successful in hard sciences, but often would not make any sense in social sciences. For example in our train experiment, it would be unreasonable to assume two individuals are exactly the same. It might be tempting to say an individual is constant enough in their beliefs from one minute to the next that we could measure their attitude before and after being on the train platform with Spanish-speakers. Even if that assumption is realistic, we have no way of proving it. 

Instead we will avoid using any assumptions of homogeneity in our statistical solution to the Fundamental Problem of Causal Inference. We can still understand something about causal effect while not seeing all potential outcomes. 

The Fundamental Problem of Causal Inference is the idea that we cannot observe multiple potential outcomes for the *same unit* at the *exact same time*. There are multiple approaches to overcoming this problem to understand causal effect. We use a statistical approach that does not assume homogeneity across units or time.

### Stable unit treatment value assumption (SUTVA)

One important assumption for causal inference is that "the [potential outcome] observation on one unit should be unaffected by the particular assignment of treatments to the other units."^[Cox 1958, §2.4.] This is called the **Stable Unit Treatment Value Assumption** (**SUTVA**). 

In the context of our example, Yao's attitude should not depend on Emma's. But what if it does? Suppose that upon hearing Spanish on the platform, Emma makes a comment to Yao about immigration which shifts his opinion. Yao might not have thought anything of the Spanish being spoken nearby, but Emma's comment changes his individual survey answers. Therefore, his outcome will depend on both which treatment he received and which treatment Emma receives.

SUTVA violation makes causal inference more difficult. We can account for dependent observations by considering more treatments. We create 4 treatments by taking into account whether or not Emma receives treatment:

`r margin_note("t = treated, c = control")`
```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Yao"),
       ct = "10",
       tt = "9",
       cc = "13",
       tc = "12") %>%
  
  # Then, we use the gt function to make it pretty.
  
  gt() %>%
  cols_label(subject = md("ID"),
             ct = md("Yao = c,<br />Emma = t"),
             tt = md("Yao = t,<br />Emma = t"),
             cc = md("Yao = c,<br />Emma = c"),
             tc = md("Yao = t,<br />Emma = c")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "Outcomes", vars(ct, tt, cc, tc))
```

Recall that a causal effect is defined as the difference between two potential outcomes. In this case, there are multiple causal effects because there are more than two potential outcomes:

`r margin_note("(Yao = t & Emma = t) - (Yao = c & Emma = t)")`
- One is the causal effect on Yao when Emma receives treatment ($9-10$).
`r margin_note("(Yao = t & Emma = c) - (Yao = c & Emma = c)")`
- Another is the causal effect  on Yao when Emma does not receive treatment ($12-13$).
`r margin_note("(Yao = c & Emma = t) - (Yao = c & Emma = c)")`
- A third is the causal effect of Emma's treatment on Yao when Yao is not treated ($10-12$). In other words, we can define a causal effect on Yao even in situation in which Yao's treatment is identical in both situations.

Note that Emma being treated has a larger causal effect on Yao than Yao himself being treated!

By considering more potential outcomes in this way, we can cause SUTVA to hold. However, if any units other than Yao are dependent on Emma (like someone overhears Emma), then we must consider further potential outcomes. The greater the number of dependent units, the more potential outcomes we must consider and the more complex the calculations become (consider an experiment with 20 different people, each of whose treatment status can affect outcomes for every one else). In order (easily) to estimate the causal effect of a single treatment relative to a control, SUTVA should hold. 

### Correlation with Potential Outcomes

When considering the relationship between a treatment and an outcome, one of the most important assumptions is a lack of correlation between treatment assignment and the potential outcomes. Consider a version of the train experiment. Assume that, if a Republican is not on the platform with Spanish-speakers, they will have an attitude value of X. If they were on a platform where they could hear Spanish, their attitude would have been X + 2. A Democrat would have an attitude X regardless of whether or not they are on the platform with Spanish-speakers. In other words, the causal effect of being in the treatment group is +2 for Republicans, and 0 for Democrats. If we could run an experiment with random assignment, we would discover that the average causal effect is somewhere between 0 and 2, depending on the relative proportion of the Republicans and Democrats.

`r margin_note("Let's say here attitude X is 9.")`
```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("R", "R", "D", "R", "D"),
       ytreat = c("11", "11", "9", "11", "9"),
       ycontrol = c("9", "9", "9", "9", "9"),
       ydiff = c("+2", "+2", "0", "+2", "0")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  cols_move(columns = vars(ytreat, ycontrol), after = vars(subject)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol)) %>%
  tab_spanner(label = "$$\\text{Estimand}$$", vars(ydiff)) %>%
  fmt_markdown(columns = TRUE)
```

Unfortunately (?), people do not choose to ride certain trains randomly. We might assume/hope that there is no correlation between which train you ride and potential outcomes. If this is true, then we would still be able to estimate the causal effect. Yet that is rarely true in general. What if, instead, all the Republicans are in the control group, and all the Democrats are in the treated? In that case, everyone has an attidue of X! And it appears that the presence of Spanish-speakers on the platform "does not matter". The correlation between treatment and potential outcomes invalidates the naive estimate of the average treatment effect.

`r margin_note("Say all the Republicans ride trains from Platform 1 (control), and all Democrats ride Platform 2 (treated). Here we find an estimated ATE of 0.")`
```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("R", "R", "D", "R", "D"),
       ytreat = c("?", "?", "9", "?", "9"),
       ycontrol = c("9", "9", "?", "9", "?"),
       ydiff = c("?", "?", "?", "?", "?")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("ID"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  cols_move(columns = vars(ytreat, ycontrol), after = vars(subject)) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject)))  %>%
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = vars(subject))) %>%
  cols_align(align = "center", columns = TRUE) %>%
  cols_align(align = "left", columns = vars(subject)) %>%
  tab_spanner(label = "$$\\text{Outcomes}$$", vars(ytreat, ycontrol)) %>%
  tab_spanner(label = "$$\\text{Estimand}$$", vars(ydiff)) %>%
  fmt_markdown(columns = TRUE)
```

Keep in mind that the problem arises when there is a correlation between treatment assignment and *potential* outcome, not simply a correlation between treatment assignment and outcome. In this case, the correlation between treatment assignment and outcome is zero! Everyone has the same salary. Just looking at the outcomes we observe is not enough. We must make assumptions about the outcomes we don't observe, about what would have happened.

### Estimand Validity 

`r margin_note("Think about how Wisdom is relevant throughout this section!")`
Recall the governor's experiment where we wanted to understand the causal effect of being elected governor on longevity. We so far have discussed that we only care about Americans over 30, because for people younger than that it is impossible to be elected governor, so they only have one potential outcome column. We have also talked about how we cannot randomize the experiment because being elected governor is not a random process. As is often the case in the real world, this experiment has even more complexities we should consider. 

As we decided earlier, it is best to use data from close elections to estimate the causal effect of being elected governor on life length. Now we should think about the relevance of that estimand (average causal effect). Say we find that being elected governor increases life length by 5 years. We have already narrowed down the relevant population we might want to generalize to as Americans over 30. 

Does it then make sense to say that if Preceptor was elected governor he would live for 5 more years? Maybe, but is there any real chance of Preceptor being elected governor? Not really! (Because he's not running, not because he wouldn't have the vote of his Gov 50 students). 

With that in mind, what is the estimand we are truly interested in? We really only care about the causal effect on people elected governor. This estimand is called the causal effect on the treated. 

This brings up a crucial point of the importance of choosing appropriate estimands. This is a relevant concept in real world experiments, like testing the effectiveness of a certain drug. For example, two estimands someone might be interested are the effectiveness of the drug as actually taken (de facto) and the effectiveness of the drug if taken as directed (de jure).^[Mallinckrodt et al. 2017] Choices in estimand could impact big decisions like if a drug is approved or not. 

Choosing a relevant estimand is another example of when Wisdom is very necessary in data science. Although in this chapter we have discussed lots of concepts at the surface level, it is important to keep in mind how these same questions and assumptions can have serious implications in the real world.

### Natural Experiments: Hormone Replacement Therapy

`r margin_note("If you've forgotten since the start of the chapter, Don Rubin is the creator of the Rubin Causal Model and this is his quote!")`
Consider - 

> "We should not avoid discussing the scientific context of any statistical problem, because this can greatly affect the resulting inference." ^[Rubin 2011]
`r tufte::quote_footer('--- Don Rubin')`

```{r echo=FALSE, fig.margin = TRUE}
knitr::include_graphics("03-rubin-causal-model/images/HRT.png")
```

Hormone replacement therapy (HRT) is an example of a 'natural experiment' that was extremely biased and therefore had serious negative consequences for many people. Hormone replacement therapy gained traction in the mid-1990's as a successful way to reduce risk of cardiovascular disease in women. Many women were put on long-term estrogen replacement therapy because of its supposed benefits to prevent cardiovascular disease. Once randomized trials happened, this belief was quickly overturned as it was found that HRT was in fact not beneficial at all.

How did people come to the conclusion that HRT was beneficial when it was not? This was an example of extreme bias in the assignment mechanism of the groups being compared. In the original study, the women who chose to take HRT were fundamentally different than those who did not. In this case, there was "healthy user bias", so the women who chose HRT were different from those who did not in ways that reduced potential negative health risks (they tended to be more generally 'health consicious', exercise more, visit the doctors). They also may have been better at adhering to prescriptions, which also correlates with likelihood to do other healthy things consistently like exercise and diet. Socioeconomic status was also not adjusted for in the original study.

Randomized trials rapidly proved HRT to be harmful rather than beneficial. Women who began taking HRT because of its supposed health benefits were hurt through this process. Lack of consideration of confounding, randomization, and heterogenous treatment effects all had serious negative effects on real people. 

## Conclusion

```{r, echo=FALSE}
knitr::include_app("https://www.youtube.com/embed/PA5tKcGNFTk")
```

The causal effect of a treatment on a single unit at a point in time is the difference between the outcome variable with the treatment and without the treatment. The fundamental problem of causal inference is that it is impossible to observe the causal effect on a single unit. As a consequence, assumptions---models---must be used in order to estimate the missing data.

`r margin_note("We start with the Enos train study, which aims to understand how proximity to people speaking Spanish might impact peoples attitudes towards immigrants. Our data is based off of a survey that gives a numerical representation of attitude. We want to understand treatment effect, so our estimand of focus is ATE. We have discussed the fundamental problem of causal inference, and the concept that ev erything is a missing data problem.")`

> "We should start the inferential process with clear statements of scientific objectives and associated estimands, and a precise description of the hypothetical data set from which we would simply calculate the estimands. Such a data set could be composed mostly of unobserved or even unobservable values, but it defines the objects of inference. 

`r margin_note("We have considered the assignment mechanism, and different ways confounding can be introduced in our data.")`

> "Then we should think about the mechanism that led to observed values being observed and unobserved values being missing. To me, statistical inference concerns estimating missing values from observed values rather than pondering p-values, and one cannot even begin to do this without assuming something about the process that created the missing values: was it, for example, simple random sampling or was it a censoring mechanism?

`r margin_note("We have also discussed some ways in which we can fill the missing values in our data.")`

> "This inferential process is most directly conceptualized as finding the probability distribution of missing values given observed values and scientific assumptions, i.e., formally, finding the posterior predictive distribution of the missing values, whence the posterior distribution of the estimands can be calculated.

`r margin_note("Models require assumptions. The assumptions we make should not be taken lightly, as they can have real world impacts, as we saw in the hormonal replacement therapy example.")`

> "There is no need to teach technical details of this Bayesian approach; instead we can use ideas based on simulating the unknowns under scientifically motivated models. We should not avoid discussing the scientific context of any statistical problem, because this can greatly affect the resulting inference. The approach of distributionally filling in (or multiply imputing) the missing values is intuitive and reveals the natural uncertainty of inference. ... 

> "After understanding this natural approach to access uncertainty of inference, then we can teach the importance of evaluating operating characteristics of such procedures." ^[Rubin 2011]

`r tufte::quote_footer('--- Don Rubin')`

<!-- ## References -->


<!-- Barfort, S., Klemmensen, R., & Larsen, E. (2020). Longevity returns to political office. Political Science Research and Methods, 1-7. doi:10.1017/psrm.2019.63 -->

<!-- Cox, D. R. (1958). *Planning of Experiments.* Wiley. -->

<!-- Holland, Paul W. (1986). "Statistics and Causal Inference." *J. Amer. Statist. Assoc.* 81 (396): 945–960. doi:10.1080/01621459.1986.10478354. -->

<!-- Mallinckrodt, Craig; Molenberghs, Geert & Rathmann, Suchitrita (2017) Choosing estimands in clinical trials with missing data. Pharmaceutical Statistics, 16(1), p. 29-36. -->

<!-- Rubin (2011, page 288), Discussion of “Towards more accessible conceptions of statistical inferences” by C. J. Wild, M. Pfannkuch, M. Regan and N. J. Horton, Journal of the Royal Statistical Society. Series A (Statistics in Society), Vol. 174, No. 2 (APRIL 2011), pp. 247-295. -->

